// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
import * as utilities from "../utilities";

/**
 * Log service data delivery management, this service provides the function of delivering data in logstore to oss product storage. [Refer to details](https://www.alibabacloud.com/help/en/log-service/latest/ship-logs-to-oss-new-version).
 *
 * > **NOTE:** This resource is no longer maintained. It is recommended to use the new resource alicloud_sls_oss_export_sink.
 * Refer to details.
 *
 * > **NOTE:** Available since v1.187.0.
 *
 * ## Example Usage
 *
 * Basic Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as alicloud from "@pulumi/alicloud";
 * import * as random from "@pulumi/random";
 *
 * const _default = new random.index.Integer("default", {
 *     max: 99999,
 *     min: 10000,
 * });
 * const example = new alicloud.log.Project("example", {
 *     projectName: `terraform-example-${_default.result}`,
 *     description: "terraform-example",
 *     tags: {
 *         Created: "TF",
 *         For: "example",
 *     },
 * });
 * const exampleStore = new alicloud.log.Store("example", {
 *     projectName: example.projectName,
 *     logstoreName: "example-store",
 *     retentionPeriod: 3650,
 *     shardCount: 3,
 *     autoSplit: true,
 *     maxSplitShardCount: 60,
 *     appendMeta: true,
 * });
 * const exampleOssExport = new alicloud.log.OssExport("example", {
 *     projectName: example.projectName,
 *     logstoreName: exampleStore.logstoreName,
 *     exportName: "terraform-example",
 *     displayName: "terraform-example",
 *     bucket: "example-bucket",
 *     prefix: "root",
 *     suffix: "",
 *     bufferInterval: 300,
 *     bufferSize: 250,
 *     compressType: "none",
 *     pathFormat: "%Y/%m/%d/%H/%M",
 *     contentType: "json",
 *     jsonEnableTag: true,
 *     roleArn: "role_arn_for_oss_write",
 *     logReadRoleArn: "role_arn_for_sls_read",
 *     timeZone: "+0800",
 * });
 * ```
 *
 * ## Import
 *
 * Log oss export can be imported using the id or name, e.g.
 *
 * ```sh
 * $ pulumi import alicloud:log/ossExport:OssExport example tf-log-project:tf-log-logstore:tf-log-export
 * ```
 */
export class OssExport extends pulumi.CustomResource {
    /**
     * Get an existing OssExport resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: OssExportState, opts?: pulumi.CustomResourceOptions): OssExport {
        return new OssExport(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'alicloud:log/ossExport:OssExport';

    /**
     * Returns true if the given object is an instance of OssExport.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is OssExport {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === OssExport.__pulumiType;
    }

    /**
     * The name of the oss bucket.
     */
    declare public readonly bucket: pulumi.Output<string>;
    /**
     * How often is it delivered every interval.
     */
    declare public readonly bufferInterval: pulumi.Output<number>;
    /**
     * Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
     */
    declare public readonly bufferSize: pulumi.Output<number>;
    /**
     * OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
     */
    declare public readonly compressType: pulumi.Output<string>;
    /**
     * Configure columns when `contentType` is `parquet` or `orc`.
     */
    declare public readonly configColumns: pulumi.Output<outputs.log.OssExportConfigColumn[] | undefined>;
    /**
     * Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
     * **According to the different format, please select the following parameters**
     */
    declare public readonly contentType: pulumi.Output<string>;
    /**
     * Field configuration in csv content_type.
     */
    declare public readonly csvConfigColumns: pulumi.Output<string[] | undefined>;
    /**
     * Separator configuration in csv content_type.
     */
    declare public readonly csvConfigDelimiter: pulumi.Output<string | undefined>;
    /**
     * escape in csv content_type.
     */
    declare public readonly csvConfigEscape: pulumi.Output<string | undefined>;
    /**
     * Indicates whether to write the field name to the CSV file, the default value is `false`.
     */
    declare public readonly csvConfigHeader: pulumi.Output<boolean | undefined>;
    /**
     * lineFeed in csv content_type.
     */
    declare public readonly csvConfigLinefeed: pulumi.Output<string | undefined>;
    /**
     * Invalid field content in csv content_type.
     */
    declare public readonly csvConfigNull: pulumi.Output<string | undefined>;
    /**
     * Escape character in csv content_type.
     */
    declare public readonly csvConfigQuote: pulumi.Output<string | undefined>;
    /**
     * The display name for oss export.
     */
    declare public readonly displayName: pulumi.Output<string | undefined>;
    /**
     * Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
     */
    declare public readonly exportName: pulumi.Output<string>;
    /**
     * The log from when to export to oss.
     */
    declare public readonly fromTime: pulumi.Output<number | undefined>;
    /**
     * Whether to deliver the label when `contentType` = `json`.
     */
    declare public readonly jsonEnableTag: pulumi.Output<boolean | undefined>;
    /**
     * Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `logReadRoleArn` is not set, `roleArn` is used to read logstore.
     */
    declare public readonly logReadRoleArn: pulumi.Output<string | undefined>;
    /**
     * The name of the log logstore.
     */
    declare public readonly logstoreName: pulumi.Output<string>;
    /**
     * The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
     */
    declare public readonly pathFormat: pulumi.Output<string>;
    /**
     * The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
     */
    declare public readonly prefix: pulumi.Output<string | undefined>;
    /**
     * The name of the log project. It is the only in one Alicloud account.
     */
    declare public readonly projectName: pulumi.Output<string>;
    /**
     * Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
     */
    declare public readonly roleArn: pulumi.Output<string | undefined>;
    /**
     * The suffix for the objects in which the shipped data is stored.
     */
    declare public readonly suffix: pulumi.Output<string | undefined>;
    /**
     * This time zone that is used to format the time, `+0800` e.g.
     */
    declare public readonly timeZone: pulumi.Output<string>;

    /**
     * Create a OssExport resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: OssExportArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: OssExportArgs | OssExportState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as OssExportState | undefined;
            resourceInputs["bucket"] = state?.bucket;
            resourceInputs["bufferInterval"] = state?.bufferInterval;
            resourceInputs["bufferSize"] = state?.bufferSize;
            resourceInputs["compressType"] = state?.compressType;
            resourceInputs["configColumns"] = state?.configColumns;
            resourceInputs["contentType"] = state?.contentType;
            resourceInputs["csvConfigColumns"] = state?.csvConfigColumns;
            resourceInputs["csvConfigDelimiter"] = state?.csvConfigDelimiter;
            resourceInputs["csvConfigEscape"] = state?.csvConfigEscape;
            resourceInputs["csvConfigHeader"] = state?.csvConfigHeader;
            resourceInputs["csvConfigLinefeed"] = state?.csvConfigLinefeed;
            resourceInputs["csvConfigNull"] = state?.csvConfigNull;
            resourceInputs["csvConfigQuote"] = state?.csvConfigQuote;
            resourceInputs["displayName"] = state?.displayName;
            resourceInputs["exportName"] = state?.exportName;
            resourceInputs["fromTime"] = state?.fromTime;
            resourceInputs["jsonEnableTag"] = state?.jsonEnableTag;
            resourceInputs["logReadRoleArn"] = state?.logReadRoleArn;
            resourceInputs["logstoreName"] = state?.logstoreName;
            resourceInputs["pathFormat"] = state?.pathFormat;
            resourceInputs["prefix"] = state?.prefix;
            resourceInputs["projectName"] = state?.projectName;
            resourceInputs["roleArn"] = state?.roleArn;
            resourceInputs["suffix"] = state?.suffix;
            resourceInputs["timeZone"] = state?.timeZone;
        } else {
            const args = argsOrState as OssExportArgs | undefined;
            if (args?.bucket === undefined && !opts.urn) {
                throw new Error("Missing required property 'bucket'");
            }
            if (args?.bufferInterval === undefined && !opts.urn) {
                throw new Error("Missing required property 'bufferInterval'");
            }
            if (args?.bufferSize === undefined && !opts.urn) {
                throw new Error("Missing required property 'bufferSize'");
            }
            if (args?.contentType === undefined && !opts.urn) {
                throw new Error("Missing required property 'contentType'");
            }
            if (args?.exportName === undefined && !opts.urn) {
                throw new Error("Missing required property 'exportName'");
            }
            if (args?.logstoreName === undefined && !opts.urn) {
                throw new Error("Missing required property 'logstoreName'");
            }
            if (args?.pathFormat === undefined && !opts.urn) {
                throw new Error("Missing required property 'pathFormat'");
            }
            if (args?.projectName === undefined && !opts.urn) {
                throw new Error("Missing required property 'projectName'");
            }
            if (args?.timeZone === undefined && !opts.urn) {
                throw new Error("Missing required property 'timeZone'");
            }
            resourceInputs["bucket"] = args?.bucket;
            resourceInputs["bufferInterval"] = args?.bufferInterval;
            resourceInputs["bufferSize"] = args?.bufferSize;
            resourceInputs["compressType"] = args?.compressType;
            resourceInputs["configColumns"] = args?.configColumns;
            resourceInputs["contentType"] = args?.contentType;
            resourceInputs["csvConfigColumns"] = args?.csvConfigColumns;
            resourceInputs["csvConfigDelimiter"] = args?.csvConfigDelimiter;
            resourceInputs["csvConfigEscape"] = args?.csvConfigEscape;
            resourceInputs["csvConfigHeader"] = args?.csvConfigHeader;
            resourceInputs["csvConfigLinefeed"] = args?.csvConfigLinefeed;
            resourceInputs["csvConfigNull"] = args?.csvConfigNull;
            resourceInputs["csvConfigQuote"] = args?.csvConfigQuote;
            resourceInputs["displayName"] = args?.displayName;
            resourceInputs["exportName"] = args?.exportName;
            resourceInputs["fromTime"] = args?.fromTime;
            resourceInputs["jsonEnableTag"] = args?.jsonEnableTag;
            resourceInputs["logReadRoleArn"] = args?.logReadRoleArn;
            resourceInputs["logstoreName"] = args?.logstoreName;
            resourceInputs["pathFormat"] = args?.pathFormat;
            resourceInputs["prefix"] = args?.prefix;
            resourceInputs["projectName"] = args?.projectName;
            resourceInputs["roleArn"] = args?.roleArn;
            resourceInputs["suffix"] = args?.suffix;
            resourceInputs["timeZone"] = args?.timeZone;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(OssExport.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering OssExport resources.
 */
export interface OssExportState {
    /**
     * The name of the oss bucket.
     */
    bucket?: pulumi.Input<string>;
    /**
     * How often is it delivered every interval.
     */
    bufferInterval?: pulumi.Input<number>;
    /**
     * Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
     */
    bufferSize?: pulumi.Input<number>;
    /**
     * OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
     */
    compressType?: pulumi.Input<string>;
    /**
     * Configure columns when `contentType` is `parquet` or `orc`.
     */
    configColumns?: pulumi.Input<pulumi.Input<inputs.log.OssExportConfigColumn>[]>;
    /**
     * Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
     * **According to the different format, please select the following parameters**
     */
    contentType?: pulumi.Input<string>;
    /**
     * Field configuration in csv content_type.
     */
    csvConfigColumns?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Separator configuration in csv content_type.
     */
    csvConfigDelimiter?: pulumi.Input<string>;
    /**
     * escape in csv content_type.
     */
    csvConfigEscape?: pulumi.Input<string>;
    /**
     * Indicates whether to write the field name to the CSV file, the default value is `false`.
     */
    csvConfigHeader?: pulumi.Input<boolean>;
    /**
     * lineFeed in csv content_type.
     */
    csvConfigLinefeed?: pulumi.Input<string>;
    /**
     * Invalid field content in csv content_type.
     */
    csvConfigNull?: pulumi.Input<string>;
    /**
     * Escape character in csv content_type.
     */
    csvConfigQuote?: pulumi.Input<string>;
    /**
     * The display name for oss export.
     */
    displayName?: pulumi.Input<string>;
    /**
     * Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
     */
    exportName?: pulumi.Input<string>;
    /**
     * The log from when to export to oss.
     */
    fromTime?: pulumi.Input<number>;
    /**
     * Whether to deliver the label when `contentType` = `json`.
     */
    jsonEnableTag?: pulumi.Input<boolean>;
    /**
     * Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `logReadRoleArn` is not set, `roleArn` is used to read logstore.
     */
    logReadRoleArn?: pulumi.Input<string>;
    /**
     * The name of the log logstore.
     */
    logstoreName?: pulumi.Input<string>;
    /**
     * The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
     */
    pathFormat?: pulumi.Input<string>;
    /**
     * The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
     */
    prefix?: pulumi.Input<string>;
    /**
     * The name of the log project. It is the only in one Alicloud account.
     */
    projectName?: pulumi.Input<string>;
    /**
     * Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
     */
    roleArn?: pulumi.Input<string>;
    /**
     * The suffix for the objects in which the shipped data is stored.
     */
    suffix?: pulumi.Input<string>;
    /**
     * This time zone that is used to format the time, `+0800` e.g.
     */
    timeZone?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a OssExport resource.
 */
export interface OssExportArgs {
    /**
     * The name of the oss bucket.
     */
    bucket: pulumi.Input<string>;
    /**
     * How often is it delivered every interval.
     */
    bufferInterval: pulumi.Input<number>;
    /**
     * Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
     */
    bufferSize: pulumi.Input<number>;
    /**
     * OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
     */
    compressType?: pulumi.Input<string>;
    /**
     * Configure columns when `contentType` is `parquet` or `orc`.
     */
    configColumns?: pulumi.Input<pulumi.Input<inputs.log.OssExportConfigColumn>[]>;
    /**
     * Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
     * **According to the different format, please select the following parameters**
     */
    contentType: pulumi.Input<string>;
    /**
     * Field configuration in csv content_type.
     */
    csvConfigColumns?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Separator configuration in csv content_type.
     */
    csvConfigDelimiter?: pulumi.Input<string>;
    /**
     * escape in csv content_type.
     */
    csvConfigEscape?: pulumi.Input<string>;
    /**
     * Indicates whether to write the field name to the CSV file, the default value is `false`.
     */
    csvConfigHeader?: pulumi.Input<boolean>;
    /**
     * lineFeed in csv content_type.
     */
    csvConfigLinefeed?: pulumi.Input<string>;
    /**
     * Invalid field content in csv content_type.
     */
    csvConfigNull?: pulumi.Input<string>;
    /**
     * Escape character in csv content_type.
     */
    csvConfigQuote?: pulumi.Input<string>;
    /**
     * The display name for oss export.
     */
    displayName?: pulumi.Input<string>;
    /**
     * Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
     */
    exportName: pulumi.Input<string>;
    /**
     * The log from when to export to oss.
     */
    fromTime?: pulumi.Input<number>;
    /**
     * Whether to deliver the label when `contentType` = `json`.
     */
    jsonEnableTag?: pulumi.Input<boolean>;
    /**
     * Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `logReadRoleArn` is not set, `roleArn` is used to read logstore.
     */
    logReadRoleArn?: pulumi.Input<string>;
    /**
     * The name of the log logstore.
     */
    logstoreName: pulumi.Input<string>;
    /**
     * The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
     */
    pathFormat: pulumi.Input<string>;
    /**
     * The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
     */
    prefix?: pulumi.Input<string>;
    /**
     * The name of the log project. It is the only in one Alicloud account.
     */
    projectName: pulumi.Input<string>;
    /**
     * Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
     */
    roleArn?: pulumi.Input<string>;
    /**
     * The suffix for the objects in which the shipped data is stored.
     */
    suffix?: pulumi.Input<string>;
    /**
     * This time zone that is used to format the time, `+0800` e.g.
     */
    timeZone: pulumi.Input<string>;
}
