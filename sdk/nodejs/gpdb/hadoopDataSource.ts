// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as utilities from "../utilities";

/**
 * Provides a GPDB Hadoop Data Source resource.
 *
 * Hadoop DataSource Config.
 *
 * For information about GPDB Hadoop Data Source and how to use it, see [What is Hadoop Data Source](https://www.alibabacloud.com/help/en/analyticdb/analyticdb-for-postgresql/developer-reference/api-gpdb-2016-05-03-createhadoopdatasource).
 *
 * > **NOTE:** Available since v1.230.0.
 *
 * ## Example Usage
 *
 * Basic Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as alicloud from "@pulumi/alicloud";
 *
 * const config = new pulumi.Config();
 * const name = config.get("name") || "terraform-example";
 * const _default = alicloud.getZones({
 *     availableResourceCreation: "VSwitch",
 * });
 * const defaultGetNetworks = alicloud.vpc.getNetworks({
 *     nameRegex: "^default-NODELETING$",
 * });
 * const defaultGetSwitches = defaultGetNetworks.then(defaultGetNetworks => alicloud.vpc.getSwitches({
 *     vpcId: defaultGetNetworks.ids?.[0],
 *     zoneId: "cn-beijing-h",
 * }));
 * const defaultEcsKeyPair = new alicloud.ecs.EcsKeyPair("default", {keyPairName: name});
 * const defaultSecurityGroup = new alicloud.ecs.SecurityGroup("default", {
 *     name: name,
 *     vpcId: defaultGetNetworks.then(defaultGetNetworks => defaultGetNetworks.ids?.[0]),
 * });
 * const defaultRole = new alicloud.ram.Role("default", {
 *     name: name,
 *     document: `    {
 *         "Statement": [
 *         {
 *             "Action": "sts:AssumeRole",
 *             "Effect": "Allow",
 *             "Principal": {
 *             "Service": [
 *                 "emr.aliyuncs.com",
 *                 "ecs.aliyuncs.com"
 *             ]
 *             }
 *         }
 *         ],
 *         "Version": "1"
 *     }
 * `,
 *     description: "this is a role example.",
 *     force: true,
 * });
 * const defaultGetResourceGroups = alicloud.resourcemanager.getResourceGroups({
 *     status: "OK",
 * });
 * const defaultGetKeys = alicloud.kms.getKeys({
 *     status: "Enabled",
 * });
 * const defaultCluster = new alicloud.emrv2.Cluster("default", {
 *     nodeGroups: [
 *         {
 *             vswitchIds: [defaultGetSwitches.then(defaultGetSwitches => defaultGetSwitches.ids?.[0])],
 *             instanceTypes: ["ecs.g6.xlarge"],
 *             nodeCount: 1,
 *             spotInstanceRemedy: false,
 *             dataDisks: [{
 *                 count: 3,
 *                 category: "cloud_essd",
 *                 size: 80,
 *                 performanceLevel: "PL0",
 *             }],
 *             nodeGroupName: "emr-master",
 *             paymentType: "PayAsYouGo",
 *             withPublicIp: false,
 *             gracefulShutdown: false,
 *             systemDisk: {
 *                 category: "cloud_essd",
 *                 size: 80,
 *                 performanceLevel: "PL0",
 *                 count: 1,
 *             },
 *             nodeGroupType: "MASTER",
 *         },
 *         {
 *             spotInstanceRemedy: false,
 *             nodeGroupType: "CORE",
 *             vswitchIds: [defaultGetSwitches.then(defaultGetSwitches => defaultGetSwitches.ids?.[0])],
 *             nodeCount: 2,
 *             gracefulShutdown: false,
 *             systemDisk: {
 *                 performanceLevel: "PL0",
 *                 count: 1,
 *                 category: "cloud_essd",
 *                 size: 80,
 *             },
 *             dataDisks: [{
 *                 count: 3,
 *                 performanceLevel: "PL0",
 *                 category: "cloud_essd",
 *                 size: 80,
 *             }],
 *             nodeGroupName: "emr-core",
 *             paymentType: "PayAsYouGo",
 *             instanceTypes: ["ecs.g6.xlarge"],
 *             withPublicIp: false,
 *         },
 *     ],
 *     deployMode: "NORMAL",
 *     tags: {
 *         Created: "TF",
 *         For: "example",
 *     },
 *     releaseVersion: "EMR-5.10.0",
 *     applications: [
 *         "HADOOP-COMMON",
 *         "HDFS",
 *         "YARN",
 *     ],
 *     nodeAttributes: [{
 *         zoneId: "cn-beijing-h",
 *         keyPairName: defaultEcsKeyPair.id,
 *         dataDiskEncrypted: true,
 *         dataDiskKmsKeyId: defaultGetKeys.then(defaultGetKeys => defaultGetKeys.ids?.[0]),
 *         vpcId: defaultGetNetworks.then(defaultGetNetworks => defaultGetNetworks.ids?.[0]),
 *         ramRole: defaultRole.name,
 *         securityGroupId: defaultSecurityGroup.id,
 *     }],
 *     resourceGroupId: defaultGetResourceGroups.then(defaultGetResourceGroups => defaultGetResourceGroups.ids?.[0]),
 *     clusterName: name,
 *     paymentType: "PayAsYouGo",
 *     clusterType: "DATAFLOW",
 * });
 * const defaultZoepvx = new alicloud.gpdb.Instance("defaultZoepvx", {
 *     instanceSpec: "2C8G",
 *     description: name,
 *     segNodeNum: 2,
 *     segStorageType: "cloud_essd",
 *     instanceNetworkType: "VPC",
 *     paymentType: "PayAsYouGo",
 *     sslEnabled: 0,
 *     engineVersion: "6.0",
 *     zoneId: "cn-beijing-h",
 *     vswitchId: defaultGetSwitches.then(defaultGetSwitches => defaultGetSwitches.ids?.[0]),
 *     storageSize: 50,
 *     masterCu: 4,
 *     vpcId: defaultGetNetworks.then(defaultGetNetworks => defaultGetNetworks.ids?.[0]),
 *     dbInstanceMode: "StorageElastic",
 *     engine: "gpdb",
 *     dbInstanceCategory: "Basic",
 * });
 * const defaultyOxz1K = new alicloud.gpdb.ExternalDataService("defaultyOxz1K", {
 *     serviceName: name,
 *     dbInstanceId: defaultZoepvx.id,
 *     serviceDescription: name,
 *     serviceSpec: "8",
 * });
 * const defaultHadoopDataSource = new alicloud.gpdb.HadoopDataSource("default", {
 *     hdfsConf: "aaa",
 *     dataSourceName: defaultyOxz1K.serviceName,
 *     yarnConf: "aaa",
 *     hiveConf: "aaa",
 *     hadoopCreateType: "emr",
 *     dataSourceDescription: name,
 *     mapReduceConf: "aaa",
 *     dataSourceType: "hive",
 *     hadoopCoreConf: "aaa",
 *     emrInstanceId: defaultCluster.id,
 *     dbInstanceId: defaultZoepvx.id,
 *     hadoopHostsAddress: "aaa",
 * });
 * ```
 *
 * ## Import
 *
 * GPDB Hadoop Data Source can be imported using the id, e.g.
 *
 * ```sh
 * $ pulumi import alicloud:gpdb/hadoopDataSource:HadoopDataSource example <db_instance_id>:<data_source_id>
 * ```
 */
export class HadoopDataSource extends pulumi.CustomResource {
    /**
     * Get an existing HadoopDataSource resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: HadoopDataSourceState, opts?: pulumi.CustomResourceOptions): HadoopDataSource {
        return new HadoopDataSource(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'alicloud:gpdb/hadoopDataSource:HadoopDataSource';

    /**
     * Returns true if the given object is an instance of HadoopDataSource.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is HadoopDataSource {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === HadoopDataSource.__pulumiType;
    }

    /**
     * Creation time
     */
    public /*out*/ readonly createTime!: pulumi.Output<string>;
    /**
     * Data Source Description
     */
    public readonly dataSourceDescription!: pulumi.Output<string | undefined>;
    /**
     * The data source ID.
     */
    public /*out*/ readonly dataSourceId!: pulumi.Output<number>;
    /**
     * Data Source Name
     */
    public readonly dataSourceName!: pulumi.Output<string | undefined>;
    /**
     * The type of the data source. Valid values:
     *
     * *   mysql
     * - postgresql
     *
     * *   hdfs
     * - hive
     */
    public readonly dataSourceType!: pulumi.Output<string | undefined>;
    /**
     * The instance ID.
     */
    public readonly dbInstanceId!: pulumi.Output<string>;
    /**
     * The ID of the Emr instance.
     */
    public readonly emrInstanceId!: pulumi.Output<string | undefined>;
    /**
     * The string that specifies the content of the Hadoop core-site.xml file.
     */
    public readonly hadoopCoreConf!: pulumi.Output<string | undefined>;
    /**
     * The type of the external service. Valid values:
     * - emr: E-MapReduce (EMR) Hadoop cluster.
     * - selfCreate: self-managed Hadoop cluster.
     */
    public readonly hadoopCreateType!: pulumi.Output<string | undefined>;
    /**
     * The IP address and hostname of the Hadoop cluster (data source) in the /etc/hosts file.
     */
    public readonly hadoopHostsAddress!: pulumi.Output<string | undefined>;
    /**
     * The string that specifies the content of the Hadoop hdfs-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    public readonly hdfsConf!: pulumi.Output<string | undefined>;
    /**
     * The string that specifies the content of the Hadoop hive-site.xml file. This parameter must be specified when DataSourceType is set to Hive.
     */
    public readonly hiveConf!: pulumi.Output<string | undefined>;
    /**
     * The content of the Hadoop mapred-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    public readonly mapReduceConf!: pulumi.Output<string | undefined>;
    /**
     * Data Source Status
     */
    public /*out*/ readonly status!: pulumi.Output<string>;
    /**
     * The string that specifies the content of the Hadoop yarn-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    public readonly yarnConf!: pulumi.Output<string | undefined>;

    /**
     * Create a HadoopDataSource resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: HadoopDataSourceArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: HadoopDataSourceArgs | HadoopDataSourceState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as HadoopDataSourceState | undefined;
            resourceInputs["createTime"] = state ? state.createTime : undefined;
            resourceInputs["dataSourceDescription"] = state ? state.dataSourceDescription : undefined;
            resourceInputs["dataSourceId"] = state ? state.dataSourceId : undefined;
            resourceInputs["dataSourceName"] = state ? state.dataSourceName : undefined;
            resourceInputs["dataSourceType"] = state ? state.dataSourceType : undefined;
            resourceInputs["dbInstanceId"] = state ? state.dbInstanceId : undefined;
            resourceInputs["emrInstanceId"] = state ? state.emrInstanceId : undefined;
            resourceInputs["hadoopCoreConf"] = state ? state.hadoopCoreConf : undefined;
            resourceInputs["hadoopCreateType"] = state ? state.hadoopCreateType : undefined;
            resourceInputs["hadoopHostsAddress"] = state ? state.hadoopHostsAddress : undefined;
            resourceInputs["hdfsConf"] = state ? state.hdfsConf : undefined;
            resourceInputs["hiveConf"] = state ? state.hiveConf : undefined;
            resourceInputs["mapReduceConf"] = state ? state.mapReduceConf : undefined;
            resourceInputs["status"] = state ? state.status : undefined;
            resourceInputs["yarnConf"] = state ? state.yarnConf : undefined;
        } else {
            const args = argsOrState as HadoopDataSourceArgs | undefined;
            if ((!args || args.dbInstanceId === undefined) && !opts.urn) {
                throw new Error("Missing required property 'dbInstanceId'");
            }
            resourceInputs["dataSourceDescription"] = args ? args.dataSourceDescription : undefined;
            resourceInputs["dataSourceName"] = args ? args.dataSourceName : undefined;
            resourceInputs["dataSourceType"] = args ? args.dataSourceType : undefined;
            resourceInputs["dbInstanceId"] = args ? args.dbInstanceId : undefined;
            resourceInputs["emrInstanceId"] = args ? args.emrInstanceId : undefined;
            resourceInputs["hadoopCoreConf"] = args ? args.hadoopCoreConf : undefined;
            resourceInputs["hadoopCreateType"] = args ? args.hadoopCreateType : undefined;
            resourceInputs["hadoopHostsAddress"] = args ? args.hadoopHostsAddress : undefined;
            resourceInputs["hdfsConf"] = args ? args.hdfsConf : undefined;
            resourceInputs["hiveConf"] = args ? args.hiveConf : undefined;
            resourceInputs["mapReduceConf"] = args ? args.mapReduceConf : undefined;
            resourceInputs["yarnConf"] = args ? args.yarnConf : undefined;
            resourceInputs["createTime"] = undefined /*out*/;
            resourceInputs["dataSourceId"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(HadoopDataSource.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering HadoopDataSource resources.
 */
export interface HadoopDataSourceState {
    /**
     * Creation time
     */
    createTime?: pulumi.Input<string>;
    /**
     * Data Source Description
     */
    dataSourceDescription?: pulumi.Input<string>;
    /**
     * The data source ID.
     */
    dataSourceId?: pulumi.Input<number>;
    /**
     * Data Source Name
     */
    dataSourceName?: pulumi.Input<string>;
    /**
     * The type of the data source. Valid values:
     *
     * *   mysql
     * - postgresql
     *
     * *   hdfs
     * - hive
     */
    dataSourceType?: pulumi.Input<string>;
    /**
     * The instance ID.
     */
    dbInstanceId?: pulumi.Input<string>;
    /**
     * The ID of the Emr instance.
     */
    emrInstanceId?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop core-site.xml file.
     */
    hadoopCoreConf?: pulumi.Input<string>;
    /**
     * The type of the external service. Valid values:
     * - emr: E-MapReduce (EMR) Hadoop cluster.
     * - selfCreate: self-managed Hadoop cluster.
     */
    hadoopCreateType?: pulumi.Input<string>;
    /**
     * The IP address and hostname of the Hadoop cluster (data source) in the /etc/hosts file.
     */
    hadoopHostsAddress?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop hdfs-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    hdfsConf?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop hive-site.xml file. This parameter must be specified when DataSourceType is set to Hive.
     */
    hiveConf?: pulumi.Input<string>;
    /**
     * The content of the Hadoop mapred-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    mapReduceConf?: pulumi.Input<string>;
    /**
     * Data Source Status
     */
    status?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop yarn-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    yarnConf?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a HadoopDataSource resource.
 */
export interface HadoopDataSourceArgs {
    /**
     * Data Source Description
     */
    dataSourceDescription?: pulumi.Input<string>;
    /**
     * Data Source Name
     */
    dataSourceName?: pulumi.Input<string>;
    /**
     * The type of the data source. Valid values:
     *
     * *   mysql
     * - postgresql
     *
     * *   hdfs
     * - hive
     */
    dataSourceType?: pulumi.Input<string>;
    /**
     * The instance ID.
     */
    dbInstanceId: pulumi.Input<string>;
    /**
     * The ID of the Emr instance.
     */
    emrInstanceId?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop core-site.xml file.
     */
    hadoopCoreConf?: pulumi.Input<string>;
    /**
     * The type of the external service. Valid values:
     * - emr: E-MapReduce (EMR) Hadoop cluster.
     * - selfCreate: self-managed Hadoop cluster.
     */
    hadoopCreateType?: pulumi.Input<string>;
    /**
     * The IP address and hostname of the Hadoop cluster (data source) in the /etc/hosts file.
     */
    hadoopHostsAddress?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop hdfs-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    hdfsConf?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop hive-site.xml file. This parameter must be specified when DataSourceType is set to Hive.
     */
    hiveConf?: pulumi.Input<string>;
    /**
     * The content of the Hadoop mapred-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    mapReduceConf?: pulumi.Input<string>;
    /**
     * The string that specifies the content of the Hadoop yarn-site.xml file. This parameter must be specified when DataSourceType is set to HDFS.
     */
    yarnConf?: pulumi.Input<string>;
}
