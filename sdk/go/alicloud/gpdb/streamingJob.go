// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package gpdb

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Provides a GPDB Streaming Job resource.
//
// Real-time data tasks.
//
// For information about GPDB Streaming Job and how to use it, see [What is Streaming Job](https://www.alibabacloud.com/help/en/analyticdb/analyticdb-for-postgresql/developer-reference/api-gpdb-2016-05-03-createstreamingjob).
//
// > **NOTE:** Available since v1.231.0.
//
// ## Example Usage
//
// # Basic Usage
//
// ```go
// package main
//
// import (
//
//	"encoding/json"
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/gpdb"
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/vpc"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			cfg := config.New(ctx, "")
//			name := "terraform-example"
//			if param := cfg.Get("name"); param != "" {
//				name = param
//			}
//			defaultTXqb15, err := vpc.NewNetwork(ctx, "defaultTXqb15", &vpc.NetworkArgs{
//				CidrBlock: pulumi.String("192.168.0.0/16"),
//			})
//			if err != nil {
//				return err
//			}
//			defaultaSWhbT, err := vpc.NewSwitch(ctx, "defaultaSWhbT", &vpc.SwitchArgs{
//				VpcId:     defaultTXqb15.ID(),
//				ZoneId:    pulumi.String("cn-beijing-h"),
//				CidrBlock: pulumi.String("192.168.1.0/24"),
//			})
//			if err != nil {
//				return err
//			}
//			defaulth2ghc1, err := gpdb.NewInstance(ctx, "defaulth2ghc1", &gpdb.InstanceArgs{
//				InstanceSpec:        pulumi.String("2C8G"),
//				Description:         pulumi.String(name),
//				SegNodeNum:          pulumi.Int(2),
//				SegStorageType:      pulumi.String("cloud_essd"),
//				InstanceNetworkType: pulumi.String("VPC"),
//				DbInstanceCategory:  pulumi.String("Basic"),
//				PaymentType:         pulumi.String("PayAsYouGo"),
//				SslEnabled:          pulumi.Int(0),
//				EngineVersion:       pulumi.String("6.0"),
//				ZoneId:              pulumi.String("cn-beijing-h"),
//				VswitchId:           defaultaSWhbT.ID(),
//				StorageSize:         pulumi.Int(50),
//				MasterCu:            pulumi.Int(4),
//				VpcId:               defaultTXqb15.ID(),
//				DbInstanceMode:      pulumi.String("StorageElastic"),
//				Engine:              pulumi.String("gpdb"),
//			})
//			if err != nil {
//				return err
//			}
//			default2dUszY, err := gpdb.NewStreamingDataService(ctx, "default2dUszY", &gpdb.StreamingDataServiceArgs{
//				ServiceName:        pulumi.String("example"),
//				DbInstanceId:       defaulth2ghc1.ID(),
//				ServiceDescription: pulumi.String("example"),
//				ServiceSpec:        pulumi.String("8"),
//			})
//			if err != nil {
//				return err
//			}
//			tmpJSON0, err := json.Marshal(map[string]interface{}{
//				"brokers":   "alikafka-post-cn-g4t3t4eod004-1-vpc.alikafka.aliyuncs.com:9092,alikafka-post-cn-g4t3t4eod004-2-vpc.alikafka.aliyuncs.com:9092,alikafka-post-cn-g4t3t4eod004-3-vpc.alikafka.aliyuncs.com:9092",
//				"delimiter": "|",
//				"format":    "delimited",
//				"topic":     "ziyuan_example",
//			})
//			if err != nil {
//				return err
//			}
//			json0 := string(tmpJSON0)
//			defaultcDQItu, err := gpdb.NewStreamingDataSource(ctx, "defaultcDQItu", &gpdb.StreamingDataSourceArgs{
//				DbInstanceId:          defaulth2ghc1.ID(),
//				DataSourceName:        pulumi.String("example"),
//				DataSourceConfig:      pulumi.String(json0),
//				DataSourceType:        pulumi.String("kafka"),
//				DataSourceDescription: pulumi.String("example"),
//				ServiceId:             default2dUszY.ServiceId,
//			})
//			if err != nil {
//				return err
//			}
//			_, err = gpdb.NewStreamingJob(ctx, "default", &gpdb.StreamingJobArgs{
//				Account:        pulumi.String("example_001"),
//				DestSchema:     pulumi.String("public"),
//				Mode:           pulumi.String("professional"),
//				JobName:        pulumi.String("example-kafka"),
//				JobDescription: pulumi.String("example-kafka"),
//				DestDatabase:   pulumi.String("adb_sampledata_tpch"),
//				DbInstanceId:   defaulth2ghc1.ID(),
//				DestTable:      pulumi.String("customer"),
//				DataSourceId:   defaultcDQItu.DataSourceId,
//				Password:       pulumi.String("example_001"),
//				JobConfig: pulumi.String(`ATABASE: adb_sampledata_tpch
//
// USER: example_001
// PASSWORD: example_001
// HOST: gp-2zean69451zsjj139-master.gpdb.rds.aliyuncs.com
// PORT: 5432
// KAFKA:
//
//	INPUT:
//	  SOURCE:
//	    BROKERS: alikafka-post-cn-3mp3t4ekq004-1-vpc.alikafka.aliyuncs.com:9092
//	    TOPIC: ziyuan_example
//	    FALLBACK_OFFSET: LATEST
//	  KEY:
//	    COLUMNS:
//	    - NAME: c_custkey
//	      TYPE: int
//	    FORMAT: delimited
//	    DELIMITED_OPTION:
//	      DELIMITER: \'|\'
//	  VALUE:
//	    COLUMNS:
//	    - NAME: c_comment
//	      TYPE: varchar
//	    FORMAT: delimited
//	    DELIMITED_OPTION:
//	      DELIMITER: \'|\'
//	  ERROR_LIMIT: 10
//	OUTPUT:
//	  SCHEMA: public
//	  TABLE: customer
//	  MODE: MERGE
//	  MATCH_COLUMNS:
//	  - c_custkey
//	  ORDER_COLUMNS:
//	  - c_custkey
//	  UPDATE_COLUMNS:
//	  - c_custkey
//	  MAPPING:
//	  - NAME: c_custkey
//	    EXPRESSION: c_custkey
//	COMMIT:
//	  MAX_ROW: 1000
//	  MINIMAL_INTERVAL: 1000
//	  CONSISTENCY: ATLEAST
//	POLL:
//	  BATCHSIZE: 1000
//	  TIMEOUT: 1000
//	PROPERTIES:
//	  group.id: ziyuan_example_01
//
// `),
//
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// GPDB Streaming Job can be imported using the id, e.g.
//
// ```sh
// $ pulumi import alicloud:gpdb/streamingJob:StreamingJob example <db_instance_id>:<job_id>
// ```
type StreamingJob struct {
	pulumi.CustomResourceState

	// The name of the database account.
	Account pulumi.StringPtrOutput `pulumi:"account"`
	// The delivery guarantee setting.
	//
	// Valid values:
	//
	// - ATLEAST
	// - EXACTLY
	Consistency pulumi.StringPtrOutput `pulumi:"consistency"`
	// The creation time of the resource
	CreateTime pulumi.StringOutput `pulumi:"createTime"`
	// The data source ID.
	DataSourceId pulumi.StringOutput `pulumi:"dataSourceId"`
	// The instance ID.
	DbInstanceId pulumi.StringOutput `pulumi:"dbInstanceId"`
	// Target Field
	DestColumns pulumi.StringArrayOutput `pulumi:"destColumns"`
	// The name of the destination database.
	DestDatabase pulumi.StringPtrOutput `pulumi:"destDatabase"`
	// Target Schema
	DestSchema pulumi.StringPtrOutput `pulumi:"destSchema"`
	// The name of the destination table.
	DestTable pulumi.StringPtrOutput `pulumi:"destTable"`
	// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
	ErrorLimitCount pulumi.IntPtrOutput `pulumi:"errorLimitCount"`
	// Automatic offset reset
	FallbackOffset pulumi.StringPtrOutput `pulumi:"fallbackOffset"`
	// Group Name
	GroupName pulumi.StringPtrOutput `pulumi:"groupName"`
	// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
	JobConfig pulumi.StringPtrOutput `pulumi:"jobConfig"`
	// The description of the job.
	JobDescription pulumi.StringPtrOutput `pulumi:"jobDescription"`
	// The job ID.
	JobId pulumi.StringOutput `pulumi:"jobId"`
	// The name of the job.
	JobName pulumi.StringOutput `pulumi:"jobName"`
	// Match Field
	MatchColumns pulumi.StringArrayOutput `pulumi:"matchColumns"`
	// The configuration mode. Valid values:
	//
	// 1.  basic: In basic mode, you must configure the configuration parameters.
	//
	// 2.  professional: In professional mode, you can submit a YAML configuration file.
	Mode pulumi.StringPtrOutput `pulumi:"mode"`
	// The password of the database account.
	Password pulumi.StringPtrOutput `pulumi:"password"`
	// Source Field
	SrcColumns pulumi.StringArrayOutput `pulumi:"srcColumns"`
	// Service status, value:
	Status pulumi.StringOutput `pulumi:"status"`
	// Specifies whether to test the real-time job. Valid values:
	//
	// - true
	// - false
	//
	// Default value: false.
	TryRun pulumi.BoolPtrOutput `pulumi:"tryRun"`
	// Update Field
	UpdateColumns pulumi.StringArrayOutput `pulumi:"updateColumns"`
	// The write mode.
	//
	// Valid values:
	//
	// - insert
	// - update
	// - merge
	WriteMode pulumi.StringPtrOutput `pulumi:"writeMode"`
}

// NewStreamingJob registers a new resource with the given unique name, arguments, and options.
func NewStreamingJob(ctx *pulumi.Context,
	name string, args *StreamingJobArgs, opts ...pulumi.ResourceOption) (*StreamingJob, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.DataSourceId == nil {
		return nil, errors.New("invalid value for required argument 'DataSourceId'")
	}
	if args.DbInstanceId == nil {
		return nil, errors.New("invalid value for required argument 'DbInstanceId'")
	}
	if args.JobName == nil {
		return nil, errors.New("invalid value for required argument 'JobName'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource StreamingJob
	err := ctx.RegisterResource("alicloud:gpdb/streamingJob:StreamingJob", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetStreamingJob gets an existing StreamingJob resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetStreamingJob(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *StreamingJobState, opts ...pulumi.ResourceOption) (*StreamingJob, error) {
	var resource StreamingJob
	err := ctx.ReadResource("alicloud:gpdb/streamingJob:StreamingJob", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering StreamingJob resources.
type streamingJobState struct {
	// The name of the database account.
	Account *string `pulumi:"account"`
	// The delivery guarantee setting.
	//
	// Valid values:
	//
	// - ATLEAST
	// - EXACTLY
	Consistency *string `pulumi:"consistency"`
	// The creation time of the resource
	CreateTime *string `pulumi:"createTime"`
	// The data source ID.
	DataSourceId *string `pulumi:"dataSourceId"`
	// The instance ID.
	DbInstanceId *string `pulumi:"dbInstanceId"`
	// Target Field
	DestColumns []string `pulumi:"destColumns"`
	// The name of the destination database.
	DestDatabase *string `pulumi:"destDatabase"`
	// Target Schema
	DestSchema *string `pulumi:"destSchema"`
	// The name of the destination table.
	DestTable *string `pulumi:"destTable"`
	// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
	ErrorLimitCount *int `pulumi:"errorLimitCount"`
	// Automatic offset reset
	FallbackOffset *string `pulumi:"fallbackOffset"`
	// Group Name
	GroupName *string `pulumi:"groupName"`
	// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
	JobConfig *string `pulumi:"jobConfig"`
	// The description of the job.
	JobDescription *string `pulumi:"jobDescription"`
	// The job ID.
	JobId *string `pulumi:"jobId"`
	// The name of the job.
	JobName *string `pulumi:"jobName"`
	// Match Field
	MatchColumns []string `pulumi:"matchColumns"`
	// The configuration mode. Valid values:
	//
	// 1.  basic: In basic mode, you must configure the configuration parameters.
	//
	// 2.  professional: In professional mode, you can submit a YAML configuration file.
	Mode *string `pulumi:"mode"`
	// The password of the database account.
	Password *string `pulumi:"password"`
	// Source Field
	SrcColumns []string `pulumi:"srcColumns"`
	// Service status, value:
	Status *string `pulumi:"status"`
	// Specifies whether to test the real-time job. Valid values:
	//
	// - true
	// - false
	//
	// Default value: false.
	TryRun *bool `pulumi:"tryRun"`
	// Update Field
	UpdateColumns []string `pulumi:"updateColumns"`
	// The write mode.
	//
	// Valid values:
	//
	// - insert
	// - update
	// - merge
	WriteMode *string `pulumi:"writeMode"`
}

type StreamingJobState struct {
	// The name of the database account.
	Account pulumi.StringPtrInput
	// The delivery guarantee setting.
	//
	// Valid values:
	//
	// - ATLEAST
	// - EXACTLY
	Consistency pulumi.StringPtrInput
	// The creation time of the resource
	CreateTime pulumi.StringPtrInput
	// The data source ID.
	DataSourceId pulumi.StringPtrInput
	// The instance ID.
	DbInstanceId pulumi.StringPtrInput
	// Target Field
	DestColumns pulumi.StringArrayInput
	// The name of the destination database.
	DestDatabase pulumi.StringPtrInput
	// Target Schema
	DestSchema pulumi.StringPtrInput
	// The name of the destination table.
	DestTable pulumi.StringPtrInput
	// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
	ErrorLimitCount pulumi.IntPtrInput
	// Automatic offset reset
	FallbackOffset pulumi.StringPtrInput
	// Group Name
	GroupName pulumi.StringPtrInput
	// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
	JobConfig pulumi.StringPtrInput
	// The description of the job.
	JobDescription pulumi.StringPtrInput
	// The job ID.
	JobId pulumi.StringPtrInput
	// The name of the job.
	JobName pulumi.StringPtrInput
	// Match Field
	MatchColumns pulumi.StringArrayInput
	// The configuration mode. Valid values:
	//
	// 1.  basic: In basic mode, you must configure the configuration parameters.
	//
	// 2.  professional: In professional mode, you can submit a YAML configuration file.
	Mode pulumi.StringPtrInput
	// The password of the database account.
	Password pulumi.StringPtrInput
	// Source Field
	SrcColumns pulumi.StringArrayInput
	// Service status, value:
	Status pulumi.StringPtrInput
	// Specifies whether to test the real-time job. Valid values:
	//
	// - true
	// - false
	//
	// Default value: false.
	TryRun pulumi.BoolPtrInput
	// Update Field
	UpdateColumns pulumi.StringArrayInput
	// The write mode.
	//
	// Valid values:
	//
	// - insert
	// - update
	// - merge
	WriteMode pulumi.StringPtrInput
}

func (StreamingJobState) ElementType() reflect.Type {
	return reflect.TypeOf((*streamingJobState)(nil)).Elem()
}

type streamingJobArgs struct {
	// The name of the database account.
	Account *string `pulumi:"account"`
	// The delivery guarantee setting.
	//
	// Valid values:
	//
	// - ATLEAST
	// - EXACTLY
	Consistency *string `pulumi:"consistency"`
	// The data source ID.
	DataSourceId string `pulumi:"dataSourceId"`
	// The instance ID.
	DbInstanceId string `pulumi:"dbInstanceId"`
	// Target Field
	DestColumns []string `pulumi:"destColumns"`
	// The name of the destination database.
	DestDatabase *string `pulumi:"destDatabase"`
	// Target Schema
	DestSchema *string `pulumi:"destSchema"`
	// The name of the destination table.
	DestTable *string `pulumi:"destTable"`
	// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
	ErrorLimitCount *int `pulumi:"errorLimitCount"`
	// Automatic offset reset
	FallbackOffset *string `pulumi:"fallbackOffset"`
	// Group Name
	GroupName *string `pulumi:"groupName"`
	// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
	JobConfig *string `pulumi:"jobConfig"`
	// The description of the job.
	JobDescription *string `pulumi:"jobDescription"`
	// The name of the job.
	JobName string `pulumi:"jobName"`
	// Match Field
	MatchColumns []string `pulumi:"matchColumns"`
	// The configuration mode. Valid values:
	//
	// 1.  basic: In basic mode, you must configure the configuration parameters.
	//
	// 2.  professional: In professional mode, you can submit a YAML configuration file.
	Mode *string `pulumi:"mode"`
	// The password of the database account.
	Password *string `pulumi:"password"`
	// Source Field
	SrcColumns []string `pulumi:"srcColumns"`
	// Specifies whether to test the real-time job. Valid values:
	//
	// - true
	// - false
	//
	// Default value: false.
	TryRun *bool `pulumi:"tryRun"`
	// Update Field
	UpdateColumns []string `pulumi:"updateColumns"`
	// The write mode.
	//
	// Valid values:
	//
	// - insert
	// - update
	// - merge
	WriteMode *string `pulumi:"writeMode"`
}

// The set of arguments for constructing a StreamingJob resource.
type StreamingJobArgs struct {
	// The name of the database account.
	Account pulumi.StringPtrInput
	// The delivery guarantee setting.
	//
	// Valid values:
	//
	// - ATLEAST
	// - EXACTLY
	Consistency pulumi.StringPtrInput
	// The data source ID.
	DataSourceId pulumi.StringInput
	// The instance ID.
	DbInstanceId pulumi.StringInput
	// Target Field
	DestColumns pulumi.StringArrayInput
	// The name of the destination database.
	DestDatabase pulumi.StringPtrInput
	// Target Schema
	DestSchema pulumi.StringPtrInput
	// The name of the destination table.
	DestTable pulumi.StringPtrInput
	// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
	ErrorLimitCount pulumi.IntPtrInput
	// Automatic offset reset
	FallbackOffset pulumi.StringPtrInput
	// Group Name
	GroupName pulumi.StringPtrInput
	// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
	JobConfig pulumi.StringPtrInput
	// The description of the job.
	JobDescription pulumi.StringPtrInput
	// The name of the job.
	JobName pulumi.StringInput
	// Match Field
	MatchColumns pulumi.StringArrayInput
	// The configuration mode. Valid values:
	//
	// 1.  basic: In basic mode, you must configure the configuration parameters.
	//
	// 2.  professional: In professional mode, you can submit a YAML configuration file.
	Mode pulumi.StringPtrInput
	// The password of the database account.
	Password pulumi.StringPtrInput
	// Source Field
	SrcColumns pulumi.StringArrayInput
	// Specifies whether to test the real-time job. Valid values:
	//
	// - true
	// - false
	//
	// Default value: false.
	TryRun pulumi.BoolPtrInput
	// Update Field
	UpdateColumns pulumi.StringArrayInput
	// The write mode.
	//
	// Valid values:
	//
	// - insert
	// - update
	// - merge
	WriteMode pulumi.StringPtrInput
}

func (StreamingJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*streamingJobArgs)(nil)).Elem()
}

type StreamingJobInput interface {
	pulumi.Input

	ToStreamingJobOutput() StreamingJobOutput
	ToStreamingJobOutputWithContext(ctx context.Context) StreamingJobOutput
}

func (*StreamingJob) ElementType() reflect.Type {
	return reflect.TypeOf((**StreamingJob)(nil)).Elem()
}

func (i *StreamingJob) ToStreamingJobOutput() StreamingJobOutput {
	return i.ToStreamingJobOutputWithContext(context.Background())
}

func (i *StreamingJob) ToStreamingJobOutputWithContext(ctx context.Context) StreamingJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamingJobOutput)
}

// StreamingJobArrayInput is an input type that accepts StreamingJobArray and StreamingJobArrayOutput values.
// You can construct a concrete instance of `StreamingJobArrayInput` via:
//
//	StreamingJobArray{ StreamingJobArgs{...} }
type StreamingJobArrayInput interface {
	pulumi.Input

	ToStreamingJobArrayOutput() StreamingJobArrayOutput
	ToStreamingJobArrayOutputWithContext(context.Context) StreamingJobArrayOutput
}

type StreamingJobArray []StreamingJobInput

func (StreamingJobArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*StreamingJob)(nil)).Elem()
}

func (i StreamingJobArray) ToStreamingJobArrayOutput() StreamingJobArrayOutput {
	return i.ToStreamingJobArrayOutputWithContext(context.Background())
}

func (i StreamingJobArray) ToStreamingJobArrayOutputWithContext(ctx context.Context) StreamingJobArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamingJobArrayOutput)
}

// StreamingJobMapInput is an input type that accepts StreamingJobMap and StreamingJobMapOutput values.
// You can construct a concrete instance of `StreamingJobMapInput` via:
//
//	StreamingJobMap{ "key": StreamingJobArgs{...} }
type StreamingJobMapInput interface {
	pulumi.Input

	ToStreamingJobMapOutput() StreamingJobMapOutput
	ToStreamingJobMapOutputWithContext(context.Context) StreamingJobMapOutput
}

type StreamingJobMap map[string]StreamingJobInput

func (StreamingJobMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*StreamingJob)(nil)).Elem()
}

func (i StreamingJobMap) ToStreamingJobMapOutput() StreamingJobMapOutput {
	return i.ToStreamingJobMapOutputWithContext(context.Background())
}

func (i StreamingJobMap) ToStreamingJobMapOutputWithContext(ctx context.Context) StreamingJobMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamingJobMapOutput)
}

type StreamingJobOutput struct{ *pulumi.OutputState }

func (StreamingJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**StreamingJob)(nil)).Elem()
}

func (o StreamingJobOutput) ToStreamingJobOutput() StreamingJobOutput {
	return o
}

func (o StreamingJobOutput) ToStreamingJobOutputWithContext(ctx context.Context) StreamingJobOutput {
	return o
}

// The name of the database account.
func (o StreamingJobOutput) Account() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.Account }).(pulumi.StringPtrOutput)
}

// The delivery guarantee setting.
//
// Valid values:
//
// - ATLEAST
// - EXACTLY
func (o StreamingJobOutput) Consistency() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.Consistency }).(pulumi.StringPtrOutput)
}

// The creation time of the resource
func (o StreamingJobOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.CreateTime }).(pulumi.StringOutput)
}

// The data source ID.
func (o StreamingJobOutput) DataSourceId() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.DataSourceId }).(pulumi.StringOutput)
}

// The instance ID.
func (o StreamingJobOutput) DbInstanceId() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.DbInstanceId }).(pulumi.StringOutput)
}

// Target Field
func (o StreamingJobOutput) DestColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringArrayOutput { return v.DestColumns }).(pulumi.StringArrayOutput)
}

// The name of the destination database.
func (o StreamingJobOutput) DestDatabase() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.DestDatabase }).(pulumi.StringPtrOutput)
}

// Target Schema
func (o StreamingJobOutput) DestSchema() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.DestSchema }).(pulumi.StringPtrOutput)
}

// The name of the destination table.
func (o StreamingJobOutput) DestTable() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.DestTable }).(pulumi.StringPtrOutput)
}

// The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
func (o StreamingJobOutput) ErrorLimitCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.IntPtrOutput { return v.ErrorLimitCount }).(pulumi.IntPtrOutput)
}

// Automatic offset reset
func (o StreamingJobOutput) FallbackOffset() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.FallbackOffset }).(pulumi.StringPtrOutput)
}

// Group Name
func (o StreamingJobOutput) GroupName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.GroupName }).(pulumi.StringPtrOutput)
}

// The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
func (o StreamingJobOutput) JobConfig() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.JobConfig }).(pulumi.StringPtrOutput)
}

// The description of the job.
func (o StreamingJobOutput) JobDescription() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.JobDescription }).(pulumi.StringPtrOutput)
}

// The job ID.
func (o StreamingJobOutput) JobId() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.JobId }).(pulumi.StringOutput)
}

// The name of the job.
func (o StreamingJobOutput) JobName() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.JobName }).(pulumi.StringOutput)
}

// Match Field
func (o StreamingJobOutput) MatchColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringArrayOutput { return v.MatchColumns }).(pulumi.StringArrayOutput)
}

// The configuration mode. Valid values:
//
// 1.  basic: In basic mode, you must configure the configuration parameters.
//
// 2.  professional: In professional mode, you can submit a YAML configuration file.
func (o StreamingJobOutput) Mode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.Mode }).(pulumi.StringPtrOutput)
}

// The password of the database account.
func (o StreamingJobOutput) Password() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.Password }).(pulumi.StringPtrOutput)
}

// Source Field
func (o StreamingJobOutput) SrcColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringArrayOutput { return v.SrcColumns }).(pulumi.StringArrayOutput)
}

// Service status, value:
func (o StreamingJobOutput) Status() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringOutput { return v.Status }).(pulumi.StringOutput)
}

// Specifies whether to test the real-time job. Valid values:
//
// - true
// - false
//
// Default value: false.
func (o StreamingJobOutput) TryRun() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.BoolPtrOutput { return v.TryRun }).(pulumi.BoolPtrOutput)
}

// Update Field
func (o StreamingJobOutput) UpdateColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringArrayOutput { return v.UpdateColumns }).(pulumi.StringArrayOutput)
}

// The write mode.
//
// Valid values:
//
// - insert
// - update
// - merge
func (o StreamingJobOutput) WriteMode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamingJob) pulumi.StringPtrOutput { return v.WriteMode }).(pulumi.StringPtrOutput)
}

type StreamingJobArrayOutput struct{ *pulumi.OutputState }

func (StreamingJobArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*StreamingJob)(nil)).Elem()
}

func (o StreamingJobArrayOutput) ToStreamingJobArrayOutput() StreamingJobArrayOutput {
	return o
}

func (o StreamingJobArrayOutput) ToStreamingJobArrayOutputWithContext(ctx context.Context) StreamingJobArrayOutput {
	return o
}

func (o StreamingJobArrayOutput) Index(i pulumi.IntInput) StreamingJobOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *StreamingJob {
		return vs[0].([]*StreamingJob)[vs[1].(int)]
	}).(StreamingJobOutput)
}

type StreamingJobMapOutput struct{ *pulumi.OutputState }

func (StreamingJobMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*StreamingJob)(nil)).Elem()
}

func (o StreamingJobMapOutput) ToStreamingJobMapOutput() StreamingJobMapOutput {
	return o
}

func (o StreamingJobMapOutput) ToStreamingJobMapOutputWithContext(ctx context.Context) StreamingJobMapOutput {
	return o
}

func (o StreamingJobMapOutput) MapIndex(k pulumi.StringInput) StreamingJobOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *StreamingJob {
		return vs[0].(map[string]*StreamingJob)[vs[1].(string)]
	}).(StreamingJobOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*StreamingJobInput)(nil)).Elem(), &StreamingJob{})
	pulumi.RegisterInputType(reflect.TypeOf((*StreamingJobArrayInput)(nil)).Elem(), StreamingJobArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*StreamingJobMapInput)(nil)).Elem(), StreamingJobMap{})
	pulumi.RegisterOutputType(StreamingJobOutput{})
	pulumi.RegisterOutputType(StreamingJobArrayOutput{})
	pulumi.RegisterOutputType(StreamingJobMapOutput{})
}
