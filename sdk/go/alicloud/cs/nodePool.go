// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package cs

import (
	"context"
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// ## Example Usage
//
// The managed cluster configuration,
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud"
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/ecs"
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/vpc"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			cfg := config.New(ctx, "")
//			name := "tf-test"
//			if param := cfg.Get("name"); param != "" {
//				name = param
//			}
//			defaultZones, err := alicloud.GetZones(ctx, &GetZonesArgs{
//				AvailableResourceCreation: pulumi.StringRef("VSwitch"),
//			}, nil)
//			if err != nil {
//				return err
//			}
//			_, err = ecs.GetInstanceTypes(ctx, &ecs.GetInstanceTypesArgs{
//				AvailabilityZone:   pulumi.StringRef(defaultZones.Zones[0].Id),
//				CpuCoreCount:       pulumi.IntRef(2),
//				MemorySize:         pulumi.Float64Ref(4),
//				KubernetesNodeRole: pulumi.StringRef("Worker"),
//			}, nil)
//			if err != nil {
//				return err
//			}
//			defaultNetwork, err := vpc.NewNetwork(ctx, "defaultNetwork", &vpc.NetworkArgs{
//				VpcName:   pulumi.String(name),
//				CidrBlock: pulumi.String("10.1.0.0/21"),
//			})
//			if err != nil {
//				return err
//			}
//			defaultSwitch, err := vpc.NewSwitch(ctx, "defaultSwitch", &vpc.SwitchArgs{
//				VswitchName: pulumi.String(name),
//				VpcId:       defaultNetwork.ID(),
//				CidrBlock:   pulumi.String("10.1.1.0/24"),
//				ZoneId:      pulumi.String(defaultZones.Zones[0].Id),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = ecs.NewKeyPair(ctx, "defaultKeyPair", &ecs.KeyPairArgs{
//				KeyPairName: pulumi.String(name),
//			})
//			if err != nil {
//				return err
//			}
//			var defaultManagedKubernetes []*cs.ManagedKubernetes
//			for key0, _ := range 1 == true {
//				__res, err := cs.NewManagedKubernetes(ctx, fmt.Sprintf("defaultManagedKubernetes-%v", key0), &cs.ManagedKubernetesArgs{
//					ClusterSpec:               pulumi.String("ack.pro.small"),
//					IsEnterpriseSecurityGroup: pulumi.Bool(true),
//					PodCidr:                   pulumi.String("172.20.0.0/16"),
//					ServiceCidr:               pulumi.String("172.21.0.0/20"),
//					WorkerVswitchIds: pulumi.StringArray{
//						defaultSwitch.ID(),
//					},
//				})
//				if err != nil {
//					return err
//				}
//				defaultManagedKubernetes = append(defaultManagedKubernetes, __res)
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a node pool.
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				DesiredSize:        pulumi.Int(1),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// The parameter `nodeCount` are deprecated from version 1.158.0ï¼Œbut it can still works. If you want to use the new parameter `desiredSize` instead, you can update it as follows. for more information of `desiredSize`, visit [Modify the expected number of nodes in a node pool](https://www.alibabacloud.com/help/en/doc-detail/160490.html#title-mpp-3jj-oo3).
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				DesiredSize:        pulumi.Int(1),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a managed node pool. If you need to enable maintenance window, you need to set the maintenance window in `cs.ManagedKubernetes`.
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				DesiredSize:        pulumi.Int(1),
//				Management: &cs.NodePoolManagementArgs{
//					AutoRepair:     pulumi.Bool(true),
//					AutoUpgrade:    pulumi.Bool(true),
//					Surge:          pulumi.Int(1),
//					MaxUnavailable: pulumi.Int(1),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Enable automatic scaling for the node pool. `scalingConfig` is required.
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				ScalingConfig: &cs.NodePoolScalingConfigArgs{
//					MinSize: pulumi.Int(1),
//					MaxSize: pulumi.Int(10),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Enable automatic scaling for managed node pool.
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				Management: &cs.NodePoolManagementArgs{
//					AutoRepair:     pulumi.Bool(true),
//					AutoUpgrade:    pulumi.Bool(true),
//					Surge:          pulumi.Int(1),
//					MaxUnavailable: pulumi.Int(1),
//				},
//				ScalingConfig: &cs.NodePoolScalingConfigArgs{
//					MinSize: pulumi.Int(1),
//					MaxSize: pulumi.Int(10),
//					Type:    pulumi.String("cpu"),
//				},
//			}, pulumi.DependsOn([]pulumi.Resource{
//				alicloud_cs_autoscaling_config.Default,
//			}))
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a `PrePaid` node pool.
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory:  pulumi.String("cloud_efficiency"),
//				SystemDiskSize:      pulumi.Int(40),
//				KeyName:             pulumi.Any(alicloud_key_pair.Default.Key_name),
//				InstanceChargeType:  pulumi.String("PrePaid"),
//				Period:              pulumi.Int(1),
//				PeriodUnit:          pulumi.String("Month"),
//				AutoRenew:           pulumi.Bool(true),
//				AutoRenewPeriod:     pulumi.Int(1),
//				InstallCloudMonitor: pulumi.Bool(true),
//				ScalingConfig: &cs.NodePoolScalingConfigArgs{
//					MinSize: pulumi.Int(1),
//					MaxSize: pulumi.Int(10),
//					Type:    pulumi.String("cpu"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a node pool with spot instance.
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				DesiredSize:        pulumi.Int(1),
//				SpotStrategy:       pulumi.String("SpotWithPriceLimit"),
//				SpotPriceLimits: cs.NodePoolSpotPriceLimitArray{
//					&cs.NodePoolSpotPriceLimitArgs{
//						InstanceType: pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//						PriceLimit:   pulumi.String("0.70"),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Use Spot instances to create a node pool with auto-scaling enabled
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				KeyName:            pulumi.Any(alicloud_key_pair.Default.Key_name),
//				ScalingConfig: &cs.NodePoolScalingConfigArgs{
//					MinSize: pulumi.Int(1),
//					MaxSize: pulumi.Int(10),
//					Type:    pulumi.String("spot"),
//				},
//				SpotStrategy: pulumi.String("SpotWithPriceLimit"),
//				SpotPriceLimits: cs.NodePoolSpotPriceLimitArray{
//					&cs.NodePoolSpotPriceLimitArgs{
//						InstanceType: pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//						PriceLimit:   pulumi.String("0.70"),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a node pool with platform as Windows
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				InstanceChargeType: pulumi.String("PostPaid"),
//				DesiredSize:        pulumi.Int(1),
//				Password:           pulumi.String("Hello1234"),
//				Platform:           pulumi.String("Windows"),
//				ImageId:            pulumi.Any(window_image_id),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// # Add an existing node to the node pool
//
// In order to distinguish automatically created nodes, it is recommended that existing nodes be placed separately in a node pool for management.
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				InstanceChargeType: pulumi.String("PostPaid"),
//				Instances: pulumi.StringArray{
//					pulumi.String("instance_id_01"),
//					pulumi.String("instance_id_02"),
//					pulumi.String("instance_id_03"),
//				},
//				FormatDisk:       pulumi.Bool(false),
//				KeepInstanceName: pulumi.Bool(true),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// Create a node pool with customized kubelet parameters
// ```go
// package main
//
// import (
//
//	"fmt"
//
//	"github.com/pulumi/pulumi-alicloud/sdk/v3/go/alicloud/cs"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := cs.NewNodePool(ctx, "default", &cs.NodePoolArgs{
//				ClusterId: pulumi.Any(alicloud_cs_managed_kubernetes.Default[0].Id),
//				VswitchIds: pulumi.StringArray{
//					pulumi.Any(alicloud_vswitch.Default.Id),
//				},
//				InstanceTypes: pulumi.StringArray{
//					pulumi.Any(data.Alicloud_instance_types.Default.Instance_types[0].Id),
//				},
//				SystemDiskCategory: pulumi.String("cloud_efficiency"),
//				SystemDiskSize:     pulumi.Int(40),
//				InstanceChargeType: pulumi.String("PostPaid"),
//				DesiredSize:        pulumi.Int(3),
//				KubeletConfiguration: &cs.NodePoolKubeletConfigurationArgs{
//					RegistryPullQps: pulumi.String("0"),
//					RegistryBurst:   pulumi.String("0"),
//					EventRecordQps:  pulumi.String("0"),
//					EventBurst:      pulumi.String("0"),
//					EvictionHard: pulumi.AnyMap{
//						"memory.available":            pulumi.Any("1024Mi"),
//						"nodefs.available":            pulumi.Any(fmt.Sprintf("10%v", "%")),
//						"nodefs.inodesFree":           pulumi.Any("1000"),
//						"imagefs.available":           pulumi.Any(fmt.Sprintf("10%v", "%")),
//						"imagefs.inodesFree":          pulumi.Any("1000"),
//						"allocatableMemory.available": pulumi.Any("2048"),
//						"pid.available":               pulumi.Any("1000"),
//					},
//					SystemReserved: pulumi.AnyMap{
//						"cpu":               pulumi.Any("1"),
//						"memory":            pulumi.Any("1Gi"),
//						"ephemeral_storage": pulumi.Any("10Gi"),
//					},
//					KubeReserved: pulumi.AnyMap{
//						"cpu":    pulumi.Any("500m"),
//						"memory": pulumi.Any("1Gi"),
//					},
//				},
//				RolloutPolicy: &cs.NodePoolRolloutPolicyArgs{
//					MaxUnavailable: pulumi.Int(1),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// Cluster nodepool can be imported using the id, e.g. Then complete the nodepool.tf accords to the result of `terraform plan`.
//
// ```sh
//
//	$ pulumi import alicloud:cs/nodePool:NodePool alicloud_cs_kubernetes_node_pool.custom_nodepool cluster_id:nodepool_id
//
// ```
type NodePool struct {
	pulumi.CustomResourceState

	// Enable Node payment auto-renew, default is `false`.
	AutoRenew pulumi.BoolPtrOutput `pulumi:"autoRenew"`
	// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
	AutoRenewPeriod pulumi.IntPtrOutput `pulumi:"autoRenewPeriod"`
	// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
	CisEnabled pulumi.BoolPtrOutput `pulumi:"cisEnabled"`
	// The id of kubernetes cluster.
	ClusterId pulumi.StringOutput `pulumi:"clusterId"`
	// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
	CpuPolicy pulumi.StringPtrOutput `pulumi:"cpuPolicy"`
	// The data disk configurations of worker nodes, such as the disk type and disk size.
	DataDisks NodePoolDataDiskArrayOutput `pulumi:"dataDisks"`
	// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
	DeploymentSetId pulumi.StringOutput `pulumi:"deploymentSetId"`
	// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
	DesiredSize pulumi.IntOutput `pulumi:"desiredSize"`
	// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
	FormatDisk pulumi.BoolOutput `pulumi:"formatDisk"`
	// Custom Image support. Must based on CentOS7 or AliyunLinux2.
	ImageId pulumi.StringOutput `pulumi:"imageId"`
	// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
	ImageType pulumi.StringOutput `pulumi:"imageType"`
	// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
	InstallCloudMonitor pulumi.BoolPtrOutput `pulumi:"installCloudMonitor"`
	// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
	InstanceChargeType pulumi.StringPtrOutput `pulumi:"instanceChargeType"`
	// The instance type of worker node.
	InstanceTypes pulumi.StringArrayOutput `pulumi:"instanceTypes"`
	// The instance list. Add existing nodes under the same cluster VPC to the node pool.
	Instances pulumi.StringArrayOutput `pulumi:"instances"`
	// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
	InternetChargeType pulumi.StringOutput `pulumi:"internetChargeType"`
	// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
	InternetMaxBandwidthOut pulumi.IntOutput `pulumi:"internetMaxBandwidthOut"`
	// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
	KeepInstanceName pulumi.BoolOutput `pulumi:"keepInstanceName"`
	// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
	KeyName pulumi.StringPtrOutput `pulumi:"keyName"`
	// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	KmsEncryptedPassword pulumi.StringPtrOutput `pulumi:"kmsEncryptedPassword"`
	// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
	KmsEncryptionContext pulumi.MapOutput `pulumi:"kmsEncryptionContext"`
	// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
	KubeletConfiguration NodePoolKubeletConfigurationPtrOutput `pulumi:"kubeletConfiguration"`
	// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
	Labels NodePoolLabelArrayOutput `pulumi:"labels"`
	// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
	Management NodePoolManagementPtrOutput `pulumi:"management"`
	// The name of node pool.
	Name pulumi.StringOutput `pulumi:"name"`
	// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
	//
	// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
	NodeCount pulumi.IntOutput `pulumi:"nodeCount"`
	// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
	NodeNameMode pulumi.StringOutput `pulumi:"nodeNameMode"`
	// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	Password pulumi.StringPtrOutput `pulumi:"password"`
	// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
	Period pulumi.IntPtrOutput `pulumi:"period"`
	// Node payment period unit, valid value: `Month`. Default is `Month`.
	PeriodUnit pulumi.StringPtrOutput `pulumi:"periodUnit"`
	// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
	//
	// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
	Platform pulumi.StringOutput `pulumi:"platform"`
	// RDS instance list, You can choose which RDS instances whitelist to add instances to.
	RdsInstances pulumi.StringArrayOutput `pulumi:"rdsInstances"`
	// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
	ResourceGroupId pulumi.StringOutput `pulumi:"resourceGroupId"`
	// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
	RolloutPolicy NodePoolRolloutPolicyPtrOutput `pulumi:"rolloutPolicy"`
	// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
	RuntimeName pulumi.StringOutput `pulumi:"runtimeName"`
	// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
	RuntimeVersion pulumi.StringOutput `pulumi:"runtimeVersion"`
	// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
	ScalingConfig NodePoolScalingConfigPtrOutput `pulumi:"scalingConfig"`
	// (Available in 1.105.0+) Id of the Scaling Group.
	ScalingGroupId pulumi.StringOutput `pulumi:"scalingGroupId"`
	// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
	ScalingPolicy pulumi.StringOutput `pulumi:"scalingPolicy"`
	// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
	//
	// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
	SecurityGroupId pulumi.StringOutput `pulumi:"securityGroupId"`
	// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
	SecurityGroupIds pulumi.StringArrayOutput `pulumi:"securityGroupIds"`
	// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
	// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
	SocEnabled pulumi.BoolPtrOutput `pulumi:"socEnabled"`
	// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
	SpotPriceLimits NodePoolSpotPriceLimitArrayOutput `pulumi:"spotPriceLimits"`
	// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
	SpotStrategy pulumi.StringPtrOutput `pulumi:"spotStrategy"`
	// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
	SystemDiskCategory pulumi.StringPtrOutput `pulumi:"systemDiskCategory"`
	// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
	SystemDiskEncryptAlgorithm pulumi.StringPtrOutput `pulumi:"systemDiskEncryptAlgorithm"`
	// Whether to enable system disk encryption.
	SystemDiskEncrypted pulumi.BoolPtrOutput `pulumi:"systemDiskEncrypted"`
	// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
	SystemDiskKmsKey pulumi.StringPtrOutput `pulumi:"systemDiskKmsKey"`
	// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
	SystemDiskPerformanceLevel pulumi.StringPtrOutput `pulumi:"systemDiskPerformanceLevel"`
	// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
	SystemDiskSize pulumi.IntPtrOutput `pulumi:"systemDiskSize"`
	// The system disk snapshot policy id.
	SystemDiskSnapshotPolicyId pulumi.StringPtrOutput `pulumi:"systemDiskSnapshotPolicyId"`
	// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
	Tags pulumi.MapOutput `pulumi:"tags"`
	// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
	Taints NodePoolTaintArrayOutput `pulumi:"taints"`
	// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
	Unschedulable pulumi.BoolPtrOutput `pulumi:"unschedulable"`
	// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
	UserData pulumi.StringPtrOutput `pulumi:"userData"`
	// The VPC of the nodes in the node pool.
	VpcId pulumi.StringOutput `pulumi:"vpcId"`
	// The vswitches used by node pool workers.
	VswitchIds pulumi.StringArrayOutput `pulumi:"vswitchIds"`
}

// NewNodePool registers a new resource with the given unique name, arguments, and options.
func NewNodePool(ctx *pulumi.Context,
	name string, args *NodePoolArgs, opts ...pulumi.ResourceOption) (*NodePool, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.ClusterId == nil {
		return nil, errors.New("invalid value for required argument 'ClusterId'")
	}
	if args.InstanceTypes == nil {
		return nil, errors.New("invalid value for required argument 'InstanceTypes'")
	}
	if args.VswitchIds == nil {
		return nil, errors.New("invalid value for required argument 'VswitchIds'")
	}
	var resource NodePool
	err := ctx.RegisterResource("alicloud:cs/nodePool:NodePool", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetNodePool gets an existing NodePool resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetNodePool(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *NodePoolState, opts ...pulumi.ResourceOption) (*NodePool, error) {
	var resource NodePool
	err := ctx.ReadResource("alicloud:cs/nodePool:NodePool", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering NodePool resources.
type nodePoolState struct {
	// Enable Node payment auto-renew, default is `false`.
	AutoRenew *bool `pulumi:"autoRenew"`
	// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
	AutoRenewPeriod *int `pulumi:"autoRenewPeriod"`
	// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
	CisEnabled *bool `pulumi:"cisEnabled"`
	// The id of kubernetes cluster.
	ClusterId *string `pulumi:"clusterId"`
	// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
	CpuPolicy *string `pulumi:"cpuPolicy"`
	// The data disk configurations of worker nodes, such as the disk type and disk size.
	DataDisks []NodePoolDataDisk `pulumi:"dataDisks"`
	// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
	DeploymentSetId *string `pulumi:"deploymentSetId"`
	// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
	DesiredSize *int `pulumi:"desiredSize"`
	// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
	FormatDisk *bool `pulumi:"formatDisk"`
	// Custom Image support. Must based on CentOS7 or AliyunLinux2.
	ImageId *string `pulumi:"imageId"`
	// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
	ImageType *string `pulumi:"imageType"`
	// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
	InstallCloudMonitor *bool `pulumi:"installCloudMonitor"`
	// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
	InstanceChargeType *string `pulumi:"instanceChargeType"`
	// The instance type of worker node.
	InstanceTypes []string `pulumi:"instanceTypes"`
	// The instance list. Add existing nodes under the same cluster VPC to the node pool.
	Instances []string `pulumi:"instances"`
	// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
	InternetChargeType *string `pulumi:"internetChargeType"`
	// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
	InternetMaxBandwidthOut *int `pulumi:"internetMaxBandwidthOut"`
	// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
	KeepInstanceName *bool `pulumi:"keepInstanceName"`
	// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
	KeyName *string `pulumi:"keyName"`
	// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	KmsEncryptedPassword *string `pulumi:"kmsEncryptedPassword"`
	// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
	KmsEncryptionContext map[string]interface{} `pulumi:"kmsEncryptionContext"`
	// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
	KubeletConfiguration *NodePoolKubeletConfiguration `pulumi:"kubeletConfiguration"`
	// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
	Labels []NodePoolLabel `pulumi:"labels"`
	// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
	Management *NodePoolManagement `pulumi:"management"`
	// The name of node pool.
	Name *string `pulumi:"name"`
	// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
	//
	// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
	NodeCount *int `pulumi:"nodeCount"`
	// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
	NodeNameMode *string `pulumi:"nodeNameMode"`
	// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	Password *string `pulumi:"password"`
	// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
	Period *int `pulumi:"period"`
	// Node payment period unit, valid value: `Month`. Default is `Month`.
	PeriodUnit *string `pulumi:"periodUnit"`
	// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
	//
	// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
	Platform *string `pulumi:"platform"`
	// RDS instance list, You can choose which RDS instances whitelist to add instances to.
	RdsInstances []string `pulumi:"rdsInstances"`
	// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
	ResourceGroupId *string `pulumi:"resourceGroupId"`
	// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
	RolloutPolicy *NodePoolRolloutPolicy `pulumi:"rolloutPolicy"`
	// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
	RuntimeName *string `pulumi:"runtimeName"`
	// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
	RuntimeVersion *string `pulumi:"runtimeVersion"`
	// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
	ScalingConfig *NodePoolScalingConfig `pulumi:"scalingConfig"`
	// (Available in 1.105.0+) Id of the Scaling Group.
	ScalingGroupId *string `pulumi:"scalingGroupId"`
	// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
	ScalingPolicy *string `pulumi:"scalingPolicy"`
	// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
	//
	// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
	SecurityGroupId *string `pulumi:"securityGroupId"`
	// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
	SecurityGroupIds []string `pulumi:"securityGroupIds"`
	// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
	// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
	SocEnabled *bool `pulumi:"socEnabled"`
	// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
	SpotPriceLimits []NodePoolSpotPriceLimit `pulumi:"spotPriceLimits"`
	// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
	SpotStrategy *string `pulumi:"spotStrategy"`
	// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
	SystemDiskCategory *string `pulumi:"systemDiskCategory"`
	// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
	SystemDiskEncryptAlgorithm *string `pulumi:"systemDiskEncryptAlgorithm"`
	// Whether to enable system disk encryption.
	SystemDiskEncrypted *bool `pulumi:"systemDiskEncrypted"`
	// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
	SystemDiskKmsKey *string `pulumi:"systemDiskKmsKey"`
	// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
	SystemDiskPerformanceLevel *string `pulumi:"systemDiskPerformanceLevel"`
	// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
	SystemDiskSize *int `pulumi:"systemDiskSize"`
	// The system disk snapshot policy id.
	SystemDiskSnapshotPolicyId *string `pulumi:"systemDiskSnapshotPolicyId"`
	// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
	Tags map[string]interface{} `pulumi:"tags"`
	// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
	Taints []NodePoolTaint `pulumi:"taints"`
	// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
	Unschedulable *bool `pulumi:"unschedulable"`
	// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
	UserData *string `pulumi:"userData"`
	// The VPC of the nodes in the node pool.
	VpcId *string `pulumi:"vpcId"`
	// The vswitches used by node pool workers.
	VswitchIds []string `pulumi:"vswitchIds"`
}

type NodePoolState struct {
	// Enable Node payment auto-renew, default is `false`.
	AutoRenew pulumi.BoolPtrInput
	// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
	AutoRenewPeriod pulumi.IntPtrInput
	// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
	CisEnabled pulumi.BoolPtrInput
	// The id of kubernetes cluster.
	ClusterId pulumi.StringPtrInput
	// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
	CpuPolicy pulumi.StringPtrInput
	// The data disk configurations of worker nodes, such as the disk type and disk size.
	DataDisks NodePoolDataDiskArrayInput
	// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
	DeploymentSetId pulumi.StringPtrInput
	// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
	DesiredSize pulumi.IntPtrInput
	// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
	FormatDisk pulumi.BoolPtrInput
	// Custom Image support. Must based on CentOS7 or AliyunLinux2.
	ImageId pulumi.StringPtrInput
	// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
	ImageType pulumi.StringPtrInput
	// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
	InstallCloudMonitor pulumi.BoolPtrInput
	// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
	InstanceChargeType pulumi.StringPtrInput
	// The instance type of worker node.
	InstanceTypes pulumi.StringArrayInput
	// The instance list. Add existing nodes under the same cluster VPC to the node pool.
	Instances pulumi.StringArrayInput
	// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
	InternetChargeType pulumi.StringPtrInput
	// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
	InternetMaxBandwidthOut pulumi.IntPtrInput
	// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
	KeepInstanceName pulumi.BoolPtrInput
	// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
	KeyName pulumi.StringPtrInput
	// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	KmsEncryptedPassword pulumi.StringPtrInput
	// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
	KmsEncryptionContext pulumi.MapInput
	// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
	KubeletConfiguration NodePoolKubeletConfigurationPtrInput
	// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
	Labels NodePoolLabelArrayInput
	// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
	Management NodePoolManagementPtrInput
	// The name of node pool.
	Name pulumi.StringPtrInput
	// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
	//
	// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
	NodeCount pulumi.IntPtrInput
	// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
	NodeNameMode pulumi.StringPtrInput
	// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	Password pulumi.StringPtrInput
	// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
	Period pulumi.IntPtrInput
	// Node payment period unit, valid value: `Month`. Default is `Month`.
	PeriodUnit pulumi.StringPtrInput
	// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
	//
	// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
	Platform pulumi.StringPtrInput
	// RDS instance list, You can choose which RDS instances whitelist to add instances to.
	RdsInstances pulumi.StringArrayInput
	// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
	ResourceGroupId pulumi.StringPtrInput
	// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
	RolloutPolicy NodePoolRolloutPolicyPtrInput
	// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
	RuntimeName pulumi.StringPtrInput
	// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
	RuntimeVersion pulumi.StringPtrInput
	// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
	ScalingConfig NodePoolScalingConfigPtrInput
	// (Available in 1.105.0+) Id of the Scaling Group.
	ScalingGroupId pulumi.StringPtrInput
	// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
	ScalingPolicy pulumi.StringPtrInput
	// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
	//
	// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
	SecurityGroupId pulumi.StringPtrInput
	// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
	SecurityGroupIds pulumi.StringArrayInput
	// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
	// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
	SocEnabled pulumi.BoolPtrInput
	// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
	SpotPriceLimits NodePoolSpotPriceLimitArrayInput
	// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
	SpotStrategy pulumi.StringPtrInput
	// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
	SystemDiskCategory pulumi.StringPtrInput
	// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
	SystemDiskEncryptAlgorithm pulumi.StringPtrInput
	// Whether to enable system disk encryption.
	SystemDiskEncrypted pulumi.BoolPtrInput
	// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
	SystemDiskKmsKey pulumi.StringPtrInput
	// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
	SystemDiskPerformanceLevel pulumi.StringPtrInput
	// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
	SystemDiskSize pulumi.IntPtrInput
	// The system disk snapshot policy id.
	SystemDiskSnapshotPolicyId pulumi.StringPtrInput
	// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
	Tags pulumi.MapInput
	// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
	Taints NodePoolTaintArrayInput
	// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
	Unschedulable pulumi.BoolPtrInput
	// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
	UserData pulumi.StringPtrInput
	// The VPC of the nodes in the node pool.
	VpcId pulumi.StringPtrInput
	// The vswitches used by node pool workers.
	VswitchIds pulumi.StringArrayInput
}

func (NodePoolState) ElementType() reflect.Type {
	return reflect.TypeOf((*nodePoolState)(nil)).Elem()
}

type nodePoolArgs struct {
	// Enable Node payment auto-renew, default is `false`.
	AutoRenew *bool `pulumi:"autoRenew"`
	// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
	AutoRenewPeriod *int `pulumi:"autoRenewPeriod"`
	// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
	CisEnabled *bool `pulumi:"cisEnabled"`
	// The id of kubernetes cluster.
	ClusterId string `pulumi:"clusterId"`
	// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
	CpuPolicy *string `pulumi:"cpuPolicy"`
	// The data disk configurations of worker nodes, such as the disk type and disk size.
	DataDisks []NodePoolDataDisk `pulumi:"dataDisks"`
	// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
	DeploymentSetId *string `pulumi:"deploymentSetId"`
	// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
	DesiredSize *int `pulumi:"desiredSize"`
	// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
	FormatDisk *bool `pulumi:"formatDisk"`
	// Custom Image support. Must based on CentOS7 or AliyunLinux2.
	ImageId *string `pulumi:"imageId"`
	// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
	ImageType *string `pulumi:"imageType"`
	// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
	InstallCloudMonitor *bool `pulumi:"installCloudMonitor"`
	// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
	InstanceChargeType *string `pulumi:"instanceChargeType"`
	// The instance type of worker node.
	InstanceTypes []string `pulumi:"instanceTypes"`
	// The instance list. Add existing nodes under the same cluster VPC to the node pool.
	Instances []string `pulumi:"instances"`
	// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
	InternetChargeType *string `pulumi:"internetChargeType"`
	// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
	InternetMaxBandwidthOut *int `pulumi:"internetMaxBandwidthOut"`
	// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
	KeepInstanceName *bool `pulumi:"keepInstanceName"`
	// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
	KeyName *string `pulumi:"keyName"`
	// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	KmsEncryptedPassword *string `pulumi:"kmsEncryptedPassword"`
	// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
	KmsEncryptionContext map[string]interface{} `pulumi:"kmsEncryptionContext"`
	// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
	KubeletConfiguration *NodePoolKubeletConfiguration `pulumi:"kubeletConfiguration"`
	// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
	Labels []NodePoolLabel `pulumi:"labels"`
	// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
	Management *NodePoolManagement `pulumi:"management"`
	// The name of node pool.
	Name *string `pulumi:"name"`
	// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
	//
	// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
	NodeCount *int `pulumi:"nodeCount"`
	// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
	NodeNameMode *string `pulumi:"nodeNameMode"`
	// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	Password *string `pulumi:"password"`
	// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
	Period *int `pulumi:"period"`
	// Node payment period unit, valid value: `Month`. Default is `Month`.
	PeriodUnit *string `pulumi:"periodUnit"`
	// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
	//
	// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
	Platform *string `pulumi:"platform"`
	// RDS instance list, You can choose which RDS instances whitelist to add instances to.
	RdsInstances []string `pulumi:"rdsInstances"`
	// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
	ResourceGroupId *string `pulumi:"resourceGroupId"`
	// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
	RolloutPolicy *NodePoolRolloutPolicy `pulumi:"rolloutPolicy"`
	// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
	RuntimeName *string `pulumi:"runtimeName"`
	// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
	RuntimeVersion *string `pulumi:"runtimeVersion"`
	// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
	ScalingConfig *NodePoolScalingConfig `pulumi:"scalingConfig"`
	// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
	ScalingPolicy *string `pulumi:"scalingPolicy"`
	// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
	//
	// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
	SecurityGroupId *string `pulumi:"securityGroupId"`
	// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
	SecurityGroupIds []string `pulumi:"securityGroupIds"`
	// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
	// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
	SocEnabled *bool `pulumi:"socEnabled"`
	// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
	SpotPriceLimits []NodePoolSpotPriceLimit `pulumi:"spotPriceLimits"`
	// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
	SpotStrategy *string `pulumi:"spotStrategy"`
	// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
	SystemDiskCategory *string `pulumi:"systemDiskCategory"`
	// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
	SystemDiskEncryptAlgorithm *string `pulumi:"systemDiskEncryptAlgorithm"`
	// Whether to enable system disk encryption.
	SystemDiskEncrypted *bool `pulumi:"systemDiskEncrypted"`
	// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
	SystemDiskKmsKey *string `pulumi:"systemDiskKmsKey"`
	// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
	SystemDiskPerformanceLevel *string `pulumi:"systemDiskPerformanceLevel"`
	// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
	SystemDiskSize *int `pulumi:"systemDiskSize"`
	// The system disk snapshot policy id.
	SystemDiskSnapshotPolicyId *string `pulumi:"systemDiskSnapshotPolicyId"`
	// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
	Tags map[string]interface{} `pulumi:"tags"`
	// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
	Taints []NodePoolTaint `pulumi:"taints"`
	// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
	Unschedulable *bool `pulumi:"unschedulable"`
	// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
	UserData *string `pulumi:"userData"`
	// The vswitches used by node pool workers.
	VswitchIds []string `pulumi:"vswitchIds"`
}

// The set of arguments for constructing a NodePool resource.
type NodePoolArgs struct {
	// Enable Node payment auto-renew, default is `false`.
	AutoRenew pulumi.BoolPtrInput
	// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
	AutoRenewPeriod pulumi.IntPtrInput
	// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
	CisEnabled pulumi.BoolPtrInput
	// The id of kubernetes cluster.
	ClusterId pulumi.StringInput
	// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
	CpuPolicy pulumi.StringPtrInput
	// The data disk configurations of worker nodes, such as the disk type and disk size.
	DataDisks NodePoolDataDiskArrayInput
	// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
	DeploymentSetId pulumi.StringPtrInput
	// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
	DesiredSize pulumi.IntPtrInput
	// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
	FormatDisk pulumi.BoolPtrInput
	// Custom Image support. Must based on CentOS7 or AliyunLinux2.
	ImageId pulumi.StringPtrInput
	// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
	ImageType pulumi.StringPtrInput
	// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
	InstallCloudMonitor pulumi.BoolPtrInput
	// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
	InstanceChargeType pulumi.StringPtrInput
	// The instance type of worker node.
	InstanceTypes pulumi.StringArrayInput
	// The instance list. Add existing nodes under the same cluster VPC to the node pool.
	Instances pulumi.StringArrayInput
	// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
	InternetChargeType pulumi.StringPtrInput
	// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
	InternetMaxBandwidthOut pulumi.IntPtrInput
	// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
	KeepInstanceName pulumi.BoolPtrInput
	// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
	KeyName pulumi.StringPtrInput
	// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	KmsEncryptedPassword pulumi.StringPtrInput
	// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
	KmsEncryptionContext pulumi.MapInput
	// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
	KubeletConfiguration NodePoolKubeletConfigurationPtrInput
	// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
	Labels NodePoolLabelArrayInput
	// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
	Management NodePoolManagementPtrInput
	// The name of node pool.
	Name pulumi.StringPtrInput
	// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
	//
	// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
	NodeCount pulumi.IntPtrInput
	// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
	NodeNameMode pulumi.StringPtrInput
	// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
	Password pulumi.StringPtrInput
	// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
	Period pulumi.IntPtrInput
	// Node payment period unit, valid value: `Month`. Default is `Month`.
	PeriodUnit pulumi.StringPtrInput
	// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
	//
	// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
	Platform pulumi.StringPtrInput
	// RDS instance list, You can choose which RDS instances whitelist to add instances to.
	RdsInstances pulumi.StringArrayInput
	// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
	ResourceGroupId pulumi.StringPtrInput
	// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
	RolloutPolicy NodePoolRolloutPolicyPtrInput
	// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
	RuntimeName pulumi.StringPtrInput
	// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
	RuntimeVersion pulumi.StringPtrInput
	// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
	ScalingConfig NodePoolScalingConfigPtrInput
	// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
	ScalingPolicy pulumi.StringPtrInput
	// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
	//
	// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
	SecurityGroupId pulumi.StringPtrInput
	// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
	SecurityGroupIds pulumi.StringArrayInput
	// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
	// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
	SocEnabled pulumi.BoolPtrInput
	// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
	SpotPriceLimits NodePoolSpotPriceLimitArrayInput
	// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
	SpotStrategy pulumi.StringPtrInput
	// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
	SystemDiskCategory pulumi.StringPtrInput
	// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
	SystemDiskEncryptAlgorithm pulumi.StringPtrInput
	// Whether to enable system disk encryption.
	SystemDiskEncrypted pulumi.BoolPtrInput
	// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
	SystemDiskKmsKey pulumi.StringPtrInput
	// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
	SystemDiskPerformanceLevel pulumi.StringPtrInput
	// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
	SystemDiskSize pulumi.IntPtrInput
	// The system disk snapshot policy id.
	SystemDiskSnapshotPolicyId pulumi.StringPtrInput
	// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
	Tags pulumi.MapInput
	// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
	Taints NodePoolTaintArrayInput
	// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
	Unschedulable pulumi.BoolPtrInput
	// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
	UserData pulumi.StringPtrInput
	// The vswitches used by node pool workers.
	VswitchIds pulumi.StringArrayInput
}

func (NodePoolArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*nodePoolArgs)(nil)).Elem()
}

type NodePoolInput interface {
	pulumi.Input

	ToNodePoolOutput() NodePoolOutput
	ToNodePoolOutputWithContext(ctx context.Context) NodePoolOutput
}

func (*NodePool) ElementType() reflect.Type {
	return reflect.TypeOf((**NodePool)(nil)).Elem()
}

func (i *NodePool) ToNodePoolOutput() NodePoolOutput {
	return i.ToNodePoolOutputWithContext(context.Background())
}

func (i *NodePool) ToNodePoolOutputWithContext(ctx context.Context) NodePoolOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodePoolOutput)
}

// NodePoolArrayInput is an input type that accepts NodePoolArray and NodePoolArrayOutput values.
// You can construct a concrete instance of `NodePoolArrayInput` via:
//
//	NodePoolArray{ NodePoolArgs{...} }
type NodePoolArrayInput interface {
	pulumi.Input

	ToNodePoolArrayOutput() NodePoolArrayOutput
	ToNodePoolArrayOutputWithContext(context.Context) NodePoolArrayOutput
}

type NodePoolArray []NodePoolInput

func (NodePoolArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*NodePool)(nil)).Elem()
}

func (i NodePoolArray) ToNodePoolArrayOutput() NodePoolArrayOutput {
	return i.ToNodePoolArrayOutputWithContext(context.Background())
}

func (i NodePoolArray) ToNodePoolArrayOutputWithContext(ctx context.Context) NodePoolArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodePoolArrayOutput)
}

// NodePoolMapInput is an input type that accepts NodePoolMap and NodePoolMapOutput values.
// You can construct a concrete instance of `NodePoolMapInput` via:
//
//	NodePoolMap{ "key": NodePoolArgs{...} }
type NodePoolMapInput interface {
	pulumi.Input

	ToNodePoolMapOutput() NodePoolMapOutput
	ToNodePoolMapOutputWithContext(context.Context) NodePoolMapOutput
}

type NodePoolMap map[string]NodePoolInput

func (NodePoolMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*NodePool)(nil)).Elem()
}

func (i NodePoolMap) ToNodePoolMapOutput() NodePoolMapOutput {
	return i.ToNodePoolMapOutputWithContext(context.Background())
}

func (i NodePoolMap) ToNodePoolMapOutputWithContext(ctx context.Context) NodePoolMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodePoolMapOutput)
}

type NodePoolOutput struct{ *pulumi.OutputState }

func (NodePoolOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**NodePool)(nil)).Elem()
}

func (o NodePoolOutput) ToNodePoolOutput() NodePoolOutput {
	return o
}

func (o NodePoolOutput) ToNodePoolOutputWithContext(ctx context.Context) NodePoolOutput {
	return o
}

// Enable Node payment auto-renew, default is `false`.
func (o NodePoolOutput) AutoRenew() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.AutoRenew }).(pulumi.BoolPtrOutput)
}

// Node payment auto-renew period, one of `1`, `2`, `3`,`6`, `12`.
func (o NodePoolOutput) AutoRenewPeriod() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntPtrOutput { return v.AutoRenewPeriod }).(pulumi.IntPtrOutput)
}

// Whether enable worker node to support cis security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [CIS Reinforcement](https://help.aliyun.com/document_detail/223744.html).
func (o NodePoolOutput) CisEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.CisEnabled }).(pulumi.BoolPtrOutput)
}

// The id of kubernetes cluster.
func (o NodePoolOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

// Kubelet cpu policy. For Kubernetes 1.12.6 and later, its valid value is either `static` or `none`. Default to `none` and modification is not supported.
func (o NodePoolOutput) CpuPolicy() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.CpuPolicy }).(pulumi.StringPtrOutput)
}

// The data disk configurations of worker nodes, such as the disk type and disk size.
func (o NodePoolOutput) DataDisks() NodePoolDataDiskArrayOutput {
	return o.ApplyT(func(v *NodePool) NodePoolDataDiskArrayOutput { return v.DataDisks }).(NodePoolDataDiskArrayOutput)
}

// The deployment set of node pool. Specify the deploymentSet to ensure that the nodes in the node pool can be distributed on different physical machines.
func (o NodePoolOutput) DeploymentSetId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.DeploymentSetId }).(pulumi.StringOutput)
}

// The desired size of nodes of the node pool. From version 1.158.0, `desiredSize` is not required.
func (o NodePoolOutput) DesiredSize() pulumi.IntOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntOutput { return v.DesiredSize }).(pulumi.IntOutput)
}

// After you select this check box, if data disks have been attached to the specified ECS instances and the file system of the last data disk is uninitialized, the system automatically formats the last data disk to ext4 and mounts the data disk to /var/lib/docker and /var/lib/kubelet. The original data on the disk will be cleared. Make sure that you back up data in advance. If no data disk is mounted on the ECS instance, no new data disk will be purchased. Default is `false`.
func (o NodePoolOutput) FormatDisk() pulumi.BoolOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolOutput { return v.FormatDisk }).(pulumi.BoolOutput)
}

// Custom Image support. Must based on CentOS7 or AliyunLinux2.
func (o NodePoolOutput) ImageId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ImageId }).(pulumi.StringOutput)
}

// The image type, instead of `platform`. This field cannot be modified. One of `AliyunLinux`, `AliyunLinux3`, `AliyunLinux3Arm64`, `AliyunLinuxUEFI`, `CentOS`, `Windows`,`WindowsCore`,`AliyunLinux Qboot`,`ContainerOS`. If you select `Windows` or `WindowsCore`, the `passord` is required.
func (o NodePoolOutput) ImageType() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ImageType }).(pulumi.StringOutput)
}

// Install the cloud monitoring plug-in on the node, and you can view the monitoring information of the instance through the cloud monitoring console. Default is `true`.
func (o NodePoolOutput) InstallCloudMonitor() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.InstallCloudMonitor }).(pulumi.BoolPtrOutput)
}

// Node payment type. Valid values: `PostPaid`, `PrePaid`, default is `PostPaid`. If value is `PrePaid`, the arguments `period`, `periodUnit`, `autoRenew` and `autoRenewPeriod` are required.
func (o NodePoolOutput) InstanceChargeType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.InstanceChargeType }).(pulumi.StringPtrOutput)
}

// The instance type of worker node.
func (o NodePoolOutput) InstanceTypes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringArrayOutput { return v.InstanceTypes }).(pulumi.StringArrayOutput)
}

// The instance list. Add existing nodes under the same cluster VPC to the node pool.
func (o NodePoolOutput) Instances() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringArrayOutput { return v.Instances }).(pulumi.StringArrayOutput)
}

// The billing method for network usage. Valid values `PayByBandwidth` and `PayByTraffic`. Conflict with `eipInternetChargeType`, EIP and public network IP can only choose one.
func (o NodePoolOutput) InternetChargeType() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.InternetChargeType }).(pulumi.StringOutput)
}

// The maximum outbound bandwidth for the public network. Unit: Mbit/s. Valid values: 0 to 100.
func (o NodePoolOutput) InternetMaxBandwidthOut() pulumi.IntOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntOutput { return v.InternetMaxBandwidthOut }).(pulumi.IntOutput)
}

// Add an existing instance to the node pool, whether to keep the original instance name. It is recommended to set to `true`.
func (o NodePoolOutput) KeepInstanceName() pulumi.BoolOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolOutput { return v.KeepInstanceName }).(pulumi.BoolOutput)
}

// The keypair of ssh login cluster node, you have to create it first. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields. Only `keyName` is supported in the management node pool.
func (o NodePoolOutput) KeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.KeyName }).(pulumi.StringPtrOutput)
}

// An KMS encrypts password used to a cs kubernetes. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
func (o NodePoolOutput) KmsEncryptedPassword() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.KmsEncryptedPassword }).(pulumi.StringPtrOutput)
}

// An KMS encryption context used to decrypt `kmsEncryptedPassword` before creating or updating a cs kubernetes with `kmsEncryptedPassword`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set.
func (o NodePoolOutput) KmsEncryptionContext() pulumi.MapOutput {
	return o.ApplyT(func(v *NodePool) pulumi.MapOutput { return v.KmsEncryptionContext }).(pulumi.MapOutput)
}

// Kubelet configuration parameters for worker nodes. Detailed below. More information in [Kubelet Configuration](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).
func (o NodePoolOutput) KubeletConfiguration() NodePoolKubeletConfigurationPtrOutput {
	return o.ApplyT(func(v *NodePool) NodePoolKubeletConfigurationPtrOutput { return v.KubeletConfiguration }).(NodePoolKubeletConfigurationPtrOutput)
}

// A List of Kubernetes labels to assign to the nodes . Only labels that are applied with the ACK API are managed by this argument. Detailed below. More information in [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
func (o NodePoolOutput) Labels() NodePoolLabelArrayOutput {
	return o.ApplyT(func(v *NodePool) NodePoolLabelArrayOutput { return v.Labels }).(NodePoolLabelArrayOutput)
}

// Managed node pool configuration. When using a managed node pool, the node key must use `keyName`. Detailed below.
func (o NodePoolOutput) Management() NodePoolManagementPtrOutput {
	return o.ApplyT(func(v *NodePool) NodePoolManagementPtrOutput { return v.Management }).(NodePoolManagementPtrOutput)
}

// The name of node pool.
func (o NodePoolOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The worker node number of the node pool. From version 1.111.0, `nodeCount` is not required.
//
// Deprecated: Field 'node_count' has been deprecated from provider version 1.158.0. New field 'desired_size' instead.
func (o NodePoolOutput) NodeCount() pulumi.IntOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntOutput { return v.NodeCount }).(pulumi.IntOutput)
}

// Each node name consists of a prefix, an IP substring, and a suffix, the input format is `customized,<prefix>,IPSubStringLen,<suffix>`. For example "customized,aliyun.com-,5,-test", if the node IP address is 192.168.59.176, the prefix is aliyun.com-, IP substring length is 5, and the suffix is -test, the node name will be aliyun.com-59176-test.
func (o NodePoolOutput) NodeNameMode() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.NodeNameMode }).(pulumi.StringOutput)
}

// The password of ssh login cluster node. You have to specify one of `password` `keyName` `kmsEncryptedPassword` fields.
func (o NodePoolOutput) Password() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.Password }).(pulumi.StringPtrOutput)
}

// Node payment period. Its valid value is one of {1, 2, 3, 6, 12, 24, 36, 48, 60}.
func (o NodePoolOutput) Period() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntPtrOutput { return v.Period }).(pulumi.IntPtrOutput)
}

// Node payment period unit, valid value: `Month`. Default is `Month`.
func (o NodePoolOutput) PeriodUnit() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.PeriodUnit }).(pulumi.StringPtrOutput)
}

// The platform. One of `AliyunLinux`, `Windows`, `CentOS`, `WindowsCore`. If you select `Windows` or `WindowsCore`, the `passord` is required. Field `platform` has been deprecated from provider version 1.145.0. New field `imageType` instead.
//
// Deprecated: Field 'platform' has been deprecated from provider version 1.145.0. New field 'image_type' instead
func (o NodePoolOutput) Platform() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.Platform }).(pulumi.StringOutput)
}

// RDS instance list, You can choose which RDS instances whitelist to add instances to.
func (o NodePoolOutput) RdsInstances() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringArrayOutput { return v.RdsInstances }).(pulumi.StringArrayOutput)
}

// The ID of the resource group,by default these cloud resources are automatically assigned to the default resource group.
func (o NodePoolOutput) ResourceGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ResourceGroupId }).(pulumi.StringOutput)
}

// Rollout policy is used to specify the strategy when the node pool is rolling update. This field works when nodepool updating.
func (o NodePoolOutput) RolloutPolicy() NodePoolRolloutPolicyPtrOutput {
	return o.ApplyT(func(v *NodePool) NodePoolRolloutPolicyPtrOutput { return v.RolloutPolicy }).(NodePoolRolloutPolicyPtrOutput)
}

// The runtime name of containers. If not set, the cluster runtime will be used as the node pool runtime. If you select another container runtime, see [Comparison of Docker, containerd, and Sandboxed-Container](https://www.alibabacloud.com/help/doc-detail/160313.htm).
func (o NodePoolOutput) RuntimeName() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.RuntimeName }).(pulumi.StringOutput)
}

// The runtime version of containers. If not set, the cluster runtime will be used as the node pool runtime.
func (o NodePoolOutput) RuntimeVersion() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.RuntimeVersion }).(pulumi.StringOutput)
}

// Auto scaling node pool configuration. For more details, see `scalingConfig`. With auto-scaling is enabled, the nodes in the node pool will be labeled with `k8s.aliyun.com=true` to prevent system pods such as coredns, metrics-servers from being scheduled to elastic nodes, and to prevent node shrinkage from causing business abnormalities.
func (o NodePoolOutput) ScalingConfig() NodePoolScalingConfigPtrOutput {
	return o.ApplyT(func(v *NodePool) NodePoolScalingConfigPtrOutput { return v.ScalingConfig }).(NodePoolScalingConfigPtrOutput)
}

// (Available in 1.105.0+) Id of the Scaling Group.
func (o NodePoolOutput) ScalingGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ScalingGroupId }).(pulumi.StringOutput)
}

// The scaling mode. Valid values: `release`, `recycle`, default is `release`. Standard mode(release): Create and release ECS instances based on requests.Swift mode(recycle): Create, stop, and restart ECS instances based on needs. New ECS instances are only created when no stopped ECS instance is avalible. This mode further accelerates the scaling process. Apart from ECS instances that use local storage, when an ECS instance is stopped, you are only chatged for storage space.
func (o NodePoolOutput) ScalingPolicy() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.ScalingPolicy }).(pulumi.StringOutput)
}

// The security group id for worker node. Field `securityGroupId` has been deprecated from provider version 1.145.0. New field `securityGroupIds` instead.
//
// Deprecated: Field 'security_group_id' has been deprecated from provider version 1.145.0. New field 'security_group_ids' instead
func (o NodePoolOutput) SecurityGroupId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.SecurityGroupId }).(pulumi.StringOutput)
}

// Multiple security groups can be configured for a node pool. If both `securityGroupIds` and `securityGroupId` are configured, `securityGroupIds` takes effect. This field cannot be modified.
func (o NodePoolOutput) SecurityGroupIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringArrayOutput { return v.SecurityGroupIds }).(pulumi.StringArrayOutput)
}

// Whether enable worker node to support soc security reinforcement, its valid value `true` or `false`. Default to `false` and apply to `image_type/platform=AliyunLinux`, see [SOC Reinforcement](https://help.aliyun.com/document_detail/196148.html).
// > **NOTE:** It is forbidden to set both `cisEnabled` and `socEnabled` to `true`at the same time.
func (o NodePoolOutput) SocEnabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.SocEnabled }).(pulumi.BoolPtrOutput)
}

// The maximum hourly price of the instance. This parameter takes effect only when `spotStrategy` is set to `SpotWithPriceLimit`. You could enable multiple spot instances by setting this field repeatedly.
func (o NodePoolOutput) SpotPriceLimits() NodePoolSpotPriceLimitArrayOutput {
	return o.ApplyT(func(v *NodePool) NodePoolSpotPriceLimitArrayOutput { return v.SpotPriceLimits }).(NodePoolSpotPriceLimitArrayOutput)
}

// The preemption policy for the pay-as-you-go instance. This parameter takes effect only when `instanceChargeType` is set to `PostPaid`. Valid value `SpotWithPriceLimit`,`SpotAsPriceGo` and `NoSpot`.
func (o NodePoolOutput) SpotStrategy() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SpotStrategy }).(pulumi.StringPtrOutput)
}

// The system disk category of worker node. Its valid value are `cloudSsd`, `cloudEfficiency` and `cloudEssd`. Default to `cloudEfficiency`.
func (o NodePoolOutput) SystemDiskCategory() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SystemDiskCategory }).(pulumi.StringPtrOutput)
}

// The encryption Algorithm for Encrypting System Disk. It takes effect when systemDiskEncrypted is true. Valid values `aes-256` and `sm4-128`.
func (o NodePoolOutput) SystemDiskEncryptAlgorithm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SystemDiskEncryptAlgorithm }).(pulumi.StringPtrOutput)
}

// Whether to enable system disk encryption.
func (o NodePoolOutput) SystemDiskEncrypted() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.SystemDiskEncrypted }).(pulumi.BoolPtrOutput)
}

// The kms key id used to encrypt the system disk. It takes effect when systemDiskEncrypted is true.
func (o NodePoolOutput) SystemDiskKmsKey() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SystemDiskKmsKey }).(pulumi.StringPtrOutput)
}

// The performance of system disk, only valid for ESSD disk. You have to specify one of `PL0` `PL1` `PL2` `PL3` fields.
func (o NodePoolOutput) SystemDiskPerformanceLevel() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SystemDiskPerformanceLevel }).(pulumi.StringPtrOutput)
}

// The system disk category of worker node. Its valid value range [40~500] in GB. Default to `120`.
func (o NodePoolOutput) SystemDiskSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.IntPtrOutput { return v.SystemDiskSize }).(pulumi.IntPtrOutput)
}

// The system disk snapshot policy id.
func (o NodePoolOutput) SystemDiskSnapshotPolicyId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.SystemDiskSnapshotPolicyId }).(pulumi.StringPtrOutput)
}

// A Map of tags to assign to the resource. It will be applied for ECS instances finally. Detailed below.
func (o NodePoolOutput) Tags() pulumi.MapOutput {
	return o.ApplyT(func(v *NodePool) pulumi.MapOutput { return v.Tags }).(pulumi.MapOutput)
}

// A List of Kubernetes taints to assign to the nodes. Detailed below. More information in [Taints and Toleration](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).
func (o NodePoolOutput) Taints() NodePoolTaintArrayOutput {
	return o.ApplyT(func(v *NodePool) NodePoolTaintArrayOutput { return v.Taints }).(NodePoolTaintArrayOutput)
}

// Set the newly added node as unschedulable. If you want to open the scheduling option, you can open it in the node list of the console. If you are using an auto-scaling node pool, the setting will not take effect. Default is `false`.
func (o NodePoolOutput) Unschedulable() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.BoolPtrOutput { return v.Unschedulable }).(pulumi.BoolPtrOutput)
}

// Windows instances support batch and PowerShell scripts. If your script file is larger than 1 KB, we recommend that you upload the script to Object Storage Service (OSS) and pull it through the internal endpoint of your OSS bucket.
func (o NodePoolOutput) UserData() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringPtrOutput { return v.UserData }).(pulumi.StringPtrOutput)
}

// The VPC of the nodes in the node pool.
func (o NodePoolOutput) VpcId() pulumi.StringOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringOutput { return v.VpcId }).(pulumi.StringOutput)
}

// The vswitches used by node pool workers.
func (o NodePoolOutput) VswitchIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *NodePool) pulumi.StringArrayOutput { return v.VswitchIds }).(pulumi.StringArrayOutput)
}

type NodePoolArrayOutput struct{ *pulumi.OutputState }

func (NodePoolArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*NodePool)(nil)).Elem()
}

func (o NodePoolArrayOutput) ToNodePoolArrayOutput() NodePoolArrayOutput {
	return o
}

func (o NodePoolArrayOutput) ToNodePoolArrayOutputWithContext(ctx context.Context) NodePoolArrayOutput {
	return o
}

func (o NodePoolArrayOutput) Index(i pulumi.IntInput) NodePoolOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *NodePool {
		return vs[0].([]*NodePool)[vs[1].(int)]
	}).(NodePoolOutput)
}

type NodePoolMapOutput struct{ *pulumi.OutputState }

func (NodePoolMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*NodePool)(nil)).Elem()
}

func (o NodePoolMapOutput) ToNodePoolMapOutput() NodePoolMapOutput {
	return o
}

func (o NodePoolMapOutput) ToNodePoolMapOutputWithContext(ctx context.Context) NodePoolMapOutput {
	return o
}

func (o NodePoolMapOutput) MapIndex(k pulumi.StringInput) NodePoolOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *NodePool {
		return vs[0].(map[string]*NodePool)[vs[1].(string)]
	}).(NodePoolOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*NodePoolInput)(nil)).Elem(), &NodePool{})
	pulumi.RegisterInputType(reflect.TypeOf((*NodePoolArrayInput)(nil)).Elem(), NodePoolArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*NodePoolMapInput)(nil)).Elem(), NodePoolMap{})
	pulumi.RegisterOutputType(NodePoolOutput{})
	pulumi.RegisterOutputType(NodePoolArrayOutput{})
	pulumi.RegisterOutputType(NodePoolMapOutput{})
}
