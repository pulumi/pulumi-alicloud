// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AliCloud.Eflo.Inputs
{

    public sealed class ExperimentPlanTemplateTemplatePipelineEnvParamsArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Number of central processing units (CPUs) allocated. This parameter affects the processing power of the computation, especially in tasks that require a large amount of parallel processing.
        /// </summary>
        [Input("cpuPerWorker", required: true)]
        public Input<int> CpuPerWorker { get; set; } = null!;

        /// <summary>
        /// The version of CUDA(Compute Unified Device Architecture) used. CUDA is a parallel computing platform and programming model provided by NVIDIA. A specific version may affect the available GPU functions and performance optimization.
        /// </summary>
        [Input("cudaVersion")]
        public Input<string>? CudaVersion { get; set; }

        /// <summary>
        /// The version of the GPU driver used. Driver version may affect GPU performance and compatibility, so it is important to ensure that the correct version is used
        /// </summary>
        [Input("gpuDriverVersion")]
        public Input<string>? GpuDriverVersion { get; set; }

        /// <summary>
        /// Number of graphics processing units (GPUs). GPUs are a key component in deep learning and large-scale data processing, so this parameter is very important for tasks that require graphics-accelerated computing.
        /// </summary>
        [Input("gpuPerWorker", required: true)]
        public Input<int> GpuPerWorker { get; set; } = null!;

        /// <summary>
        /// The amount of memory available. Memory size has an important impact on the performance and stability of the program, especially when dealing with large data sets or high-dimensional data.
        /// </summary>
        [Input("memoryPerWorker", required: true)]
        public Input<int> MemoryPerWorker { get; set; } = null!;

        /// <summary>
        /// The NVIDIA Collective Communications Library(NCCL) version used. NCCL is a library for multi-GPU and multi-node communication. This parameter is particularly important for optimizing data transmission in distributed computing.
        /// </summary>
        [Input("ncclVersion")]
        public Input<string>? NcclVersion { get; set; }

        /// <summary>
        /// The version of the PyTorch framework used. PyTorch is a widely used deep learning library, and differences between versions may affect the performance and functional support of model training and inference.
        /// </summary>
        [Input("pyTorchVersion")]
        public Input<string>? PyTorchVersion { get; set; }

        /// <summary>
        /// Shared memory GB allocation
        /// </summary>
        [Input("shareMemory", required: true)]
        public Input<int> ShareMemory { get; set; } = null!;

        /// <summary>
        /// The total number of nodes. This parameter directly affects the parallelism and computing speed of the task, and a higher number of working nodes usually accelerates the completion of the task.
        /// </summary>
        [Input("workerNum", required: true)]
        public Input<int> WorkerNum { get; set; } = null!;

        public ExperimentPlanTemplateTemplatePipelineEnvParamsArgs()
        {
        }
        public static new ExperimentPlanTemplateTemplatePipelineEnvParamsArgs Empty => new ExperimentPlanTemplateTemplatePipelineEnvParamsArgs();
    }
}
