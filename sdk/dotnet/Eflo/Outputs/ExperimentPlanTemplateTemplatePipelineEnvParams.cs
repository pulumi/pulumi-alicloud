// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AliCloud.Eflo.Outputs
{

    [OutputType]
    public sealed class ExperimentPlanTemplateTemplatePipelineEnvParams
    {
        /// <summary>
        /// Number of central processing units (CPUs) allocated. This parameter affects the processing power of the computation, especially in tasks that require a large amount of parallel processing.
        /// </summary>
        public readonly int CpuPerWorker;
        /// <summary>
        /// The version of CUDA(Compute Unified Device Architecture) used. CUDA is a parallel computing platform and programming model provided by NVIDIA. A specific version may affect the available GPU functions and performance optimization.
        /// </summary>
        public readonly string? CudaVersion;
        /// <summary>
        /// The version of the GPU driver used. Driver version may affect GPU performance and compatibility, so it is important to ensure that the correct version is used
        /// </summary>
        public readonly string? GpuDriverVersion;
        /// <summary>
        /// Number of graphics processing units (GPUs). GPUs are a key component in deep learning and large-scale data processing, so this parameter is very important for tasks that require graphics-accelerated computing.
        /// </summary>
        public readonly int GpuPerWorker;
        /// <summary>
        /// The amount of memory available. Memory size has an important impact on the performance and stability of the program, especially when dealing with large data sets or high-dimensional data.
        /// </summary>
        public readonly int MemoryPerWorker;
        /// <summary>
        /// The NVIDIA Collective Communications Library(NCCL) version used. NCCL is a library for multi-GPU and multi-node communication. This parameter is particularly important for optimizing data transmission in distributed computing.
        /// </summary>
        public readonly string? NcclVersion;
        /// <summary>
        /// The version of the PyTorch framework used. PyTorch is a widely used deep learning library, and differences between versions may affect the performance and functional support of model training and inference.
        /// </summary>
        public readonly string? PyTorchVersion;
        /// <summary>
        /// Shared memory GB allocation
        /// </summary>
        public readonly int ShareMemory;
        /// <summary>
        /// The total number of nodes. This parameter directly affects the parallelism and computing speed of the task, and a higher number of working nodes usually accelerates the completion of the task.
        /// </summary>
        public readonly int WorkerNum;

        [OutputConstructor]
        private ExperimentPlanTemplateTemplatePipelineEnvParams(
            int cpuPerWorker,

            string? cudaVersion,

            string? gpuDriverVersion,

            int gpuPerWorker,

            int memoryPerWorker,

            string? ncclVersion,

            string? pyTorchVersion,

            int shareMemory,

            int workerNum)
        {
            CpuPerWorker = cpuPerWorker;
            CudaVersion = cudaVersion;
            GpuDriverVersion = gpuDriverVersion;
            GpuPerWorker = gpuPerWorker;
            MemoryPerWorker = memoryPerWorker;
            NcclVersion = ncclVersion;
            PyTorchVersion = pyTorchVersion;
            ShareMemory = shareMemory;
            WorkerNum = workerNum;
        }
    }
}
