// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AliCloud.Log
{
    /// <summary>
    /// Log service data delivery management, this service provides the function of delivering data in logstore to oss product storage.
    /// [Refer to details](https://www.alibabacloud.com/help/en/log-service/latest/ship-logs-to-oss-new-version).
    /// 
    /// &gt; **NOTE:** Available in 1.187.0+
    /// 
    /// ## Example Usage
    /// 
    /// Basic Usage
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using AliCloud = Pulumi.AliCloud;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var exampleProject = new AliCloud.Log.Project("exampleProject", new()
    ///     {
    ///         Description = "created by terraform",
    ///         Tags = 
    ///         {
    ///             { "test", "test" },
    ///         },
    ///     });
    /// 
    ///     var exampleStore = new AliCloud.Log.Store("exampleStore", new()
    ///     {
    ///         Project = exampleProject.Name,
    ///         RetentionPeriod = 3650,
    ///         ShardCount = 3,
    ///         AutoSplit = true,
    ///         MaxSplitShardCount = 60,
    ///         AppendMeta = true,
    ///     });
    /// 
    ///     var exampleOssExport = new AliCloud.Log.OssExport("exampleOssExport", new()
    ///     {
    ///         ProjectName = exampleProject.Name,
    ///         LogstoreName = exampleStore.Name,
    ///         ExportName = "oss_export_name",
    ///         DisplayName = "oss_export_display_name",
    ///         Bucket = "test_bucket",
    ///         Prefix = "root",
    ///         Suffix = "",
    ///         BufferInterval = 300,
    ///         BufferSize = 250,
    ///         CompressType = "none",
    ///         PathFormat = "%Y/%m/%d/%H/%M",
    ///         ContentType = "json",
    ///         JsonEnableTag = true,
    ///         RoleArn = "role_arn_for_oss_write",
    ///         LogReadRoleArn = "role_arn_for_sls_read",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Log oss export can be imported using the id or name, e.g.
    /// 
    /// ```sh
    ///  $ pulumi import alicloud:log/ossExport:OssExport example tf-log-project:tf-log-logstore:tf-log-export
    /// ```
    /// </summary>
    [AliCloudResourceType("alicloud:log/ossExport:OssExport")]
    public partial class OssExport : global::Pulumi.CustomResource
    {
        /// <summary>
        /// The name of the oss bucket.
        /// </summary>
        [Output("bucket")]
        public Output<string> Bucket { get; private set; } = null!;

        /// <summary>
        /// How often is it delivered every interval.
        /// </summary>
        [Output("bufferInterval")]
        public Output<int> BufferInterval { get; private set; } = null!;

        /// <summary>
        /// Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
        /// </summary>
        [Output("bufferSize")]
        public Output<int> BufferSize { get; private set; } = null!;

        /// <summary>
        /// OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
        /// </summary>
        [Output("compressType")]
        public Output<string> CompressType { get; private set; } = null!;

        /// <summary>
        /// Configure columns when `content_type` is `parquet` or `orc`.
        /// </summary>
        [Output("configColumns")]
        public Output<ImmutableArray<Outputs.OssExportConfigColumn>> ConfigColumns { get; private set; } = null!;

        /// <summary>
        /// Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
        /// **According to the different format, please select the following parameters**
        /// </summary>
        [Output("contentType")]
        public Output<string> ContentType { get; private set; } = null!;

        /// <summary>
        /// Field configuration in csv content_type.
        /// </summary>
        [Output("csvConfigColumns")]
        public Output<ImmutableArray<string>> CsvConfigColumns { get; private set; } = null!;

        /// <summary>
        /// Separator configuration in csv content_type.
        /// </summary>
        [Output("csvConfigDelimiter")]
        public Output<string?> CsvConfigDelimiter { get; private set; } = null!;

        /// <summary>
        /// escape in csv content_type.
        /// </summary>
        [Output("csvConfigEscape")]
        public Output<string?> CsvConfigEscape { get; private set; } = null!;

        /// <summary>
        /// Indicates whether to write the field name to the CSV file, the default value is `false`.
        /// </summary>
        [Output("csvConfigHeader")]
        public Output<bool?> CsvConfigHeader { get; private set; } = null!;

        /// <summary>
        /// lineFeed in csv content_type.
        /// </summary>
        [Output("csvConfigLinefeed")]
        public Output<string?> CsvConfigLinefeed { get; private set; } = null!;

        /// <summary>
        /// Invalid field content in csv content_type.
        /// </summary>
        [Output("csvConfigNull")]
        public Output<string?> CsvConfigNull { get; private set; } = null!;

        /// <summary>
        /// Escape character in csv content_type.
        /// </summary>
        [Output("csvConfigQuote")]
        public Output<string?> CsvConfigQuote { get; private set; } = null!;

        /// <summary>
        /// The display name for oss export.
        /// </summary>
        [Output("displayName")]
        public Output<string?> DisplayName { get; private set; } = null!;

        /// <summary>
        /// Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
        /// </summary>
        [Output("exportName")]
        public Output<string> ExportName { get; private set; } = null!;

        /// <summary>
        /// The log from when to export to oss.
        /// </summary>
        [Output("fromTime")]
        public Output<int?> FromTime { get; private set; } = null!;

        /// <summary>
        /// Whether to deliver the label when `content_type` = `json`.
        /// </summary>
        [Output("jsonEnableTag")]
        public Output<bool?> JsonEnableTag { get; private set; } = null!;

        /// <summary>
        /// Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `log_read_role_arn` is not set, `role_arn` is used to read logstore.
        /// </summary>
        [Output("logReadRoleArn")]
        public Output<string?> LogReadRoleArn { get; private set; } = null!;

        /// <summary>
        /// The name of the log logstore.
        /// </summary>
        [Output("logstoreName")]
        public Output<string> LogstoreName { get; private set; } = null!;

        /// <summary>
        /// The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
        /// </summary>
        [Output("pathFormat")]
        public Output<string> PathFormat { get; private set; } = null!;

        /// <summary>
        /// The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
        /// </summary>
        [Output("prefix")]
        public Output<string?> Prefix { get; private set; } = null!;

        /// <summary>
        /// The name of the log project. It is the only in one Alicloud account.
        /// </summary>
        [Output("projectName")]
        public Output<string> ProjectName { get; private set; } = null!;

        /// <summary>
        /// Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
        /// </summary>
        [Output("roleArn")]
        public Output<string?> RoleArn { get; private set; } = null!;

        /// <summary>
        /// The suffix for the objects in which the shipped data is stored.
        /// </summary>
        [Output("suffix")]
        public Output<string?> Suffix { get; private set; } = null!;

        /// <summary>
        /// This time zone that is used to format the time, `+0800` e.g.
        /// </summary>
        [Output("timeZone")]
        public Output<string> TimeZone { get; private set; } = null!;


        /// <summary>
        /// Create a OssExport resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public OssExport(string name, OssExportArgs args, CustomResourceOptions? options = null)
            : base("alicloud:log/ossExport:OssExport", name, args ?? new OssExportArgs(), MakeResourceOptions(options, ""))
        {
        }

        private OssExport(string name, Input<string> id, OssExportState? state = null, CustomResourceOptions? options = null)
            : base("alicloud:log/ossExport:OssExport", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing OssExport resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static OssExport Get(string name, Input<string> id, OssExportState? state = null, CustomResourceOptions? options = null)
        {
            return new OssExport(name, id, state, options);
        }
    }

    public sealed class OssExportArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the oss bucket.
        /// </summary>
        [Input("bucket", required: true)]
        public Input<string> Bucket { get; set; } = null!;

        /// <summary>
        /// How often is it delivered every interval.
        /// </summary>
        [Input("bufferInterval", required: true)]
        public Input<int> BufferInterval { get; set; } = null!;

        /// <summary>
        /// Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
        /// </summary>
        [Input("bufferSize", required: true)]
        public Input<int> BufferSize { get; set; } = null!;

        /// <summary>
        /// OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
        /// </summary>
        [Input("compressType")]
        public Input<string>? CompressType { get; set; }

        [Input("configColumns")]
        private InputList<Inputs.OssExportConfigColumnArgs>? _configColumns;

        /// <summary>
        /// Configure columns when `content_type` is `parquet` or `orc`.
        /// </summary>
        public InputList<Inputs.OssExportConfigColumnArgs> ConfigColumns
        {
            get => _configColumns ?? (_configColumns = new InputList<Inputs.OssExportConfigColumnArgs>());
            set => _configColumns = value;
        }

        /// <summary>
        /// Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
        /// **According to the different format, please select the following parameters**
        /// </summary>
        [Input("contentType", required: true)]
        public Input<string> ContentType { get; set; } = null!;

        [Input("csvConfigColumns")]
        private InputList<string>? _csvConfigColumns;

        /// <summary>
        /// Field configuration in csv content_type.
        /// </summary>
        public InputList<string> CsvConfigColumns
        {
            get => _csvConfigColumns ?? (_csvConfigColumns = new InputList<string>());
            set => _csvConfigColumns = value;
        }

        /// <summary>
        /// Separator configuration in csv content_type.
        /// </summary>
        [Input("csvConfigDelimiter")]
        public Input<string>? CsvConfigDelimiter { get; set; }

        /// <summary>
        /// escape in csv content_type.
        /// </summary>
        [Input("csvConfigEscape")]
        public Input<string>? CsvConfigEscape { get; set; }

        /// <summary>
        /// Indicates whether to write the field name to the CSV file, the default value is `false`.
        /// </summary>
        [Input("csvConfigHeader")]
        public Input<bool>? CsvConfigHeader { get; set; }

        /// <summary>
        /// lineFeed in csv content_type.
        /// </summary>
        [Input("csvConfigLinefeed")]
        public Input<string>? CsvConfigLinefeed { get; set; }

        /// <summary>
        /// Invalid field content in csv content_type.
        /// </summary>
        [Input("csvConfigNull")]
        public Input<string>? CsvConfigNull { get; set; }

        /// <summary>
        /// Escape character in csv content_type.
        /// </summary>
        [Input("csvConfigQuote")]
        public Input<string>? CsvConfigQuote { get; set; }

        /// <summary>
        /// The display name for oss export.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        /// <summary>
        /// Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
        /// </summary>
        [Input("exportName", required: true)]
        public Input<string> ExportName { get; set; } = null!;

        /// <summary>
        /// The log from when to export to oss.
        /// </summary>
        [Input("fromTime")]
        public Input<int>? FromTime { get; set; }

        /// <summary>
        /// Whether to deliver the label when `content_type` = `json`.
        /// </summary>
        [Input("jsonEnableTag")]
        public Input<bool>? JsonEnableTag { get; set; }

        /// <summary>
        /// Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `log_read_role_arn` is not set, `role_arn` is used to read logstore.
        /// </summary>
        [Input("logReadRoleArn")]
        public Input<string>? LogReadRoleArn { get; set; }

        /// <summary>
        /// The name of the log logstore.
        /// </summary>
        [Input("logstoreName", required: true)]
        public Input<string> LogstoreName { get; set; } = null!;

        /// <summary>
        /// The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
        /// </summary>
        [Input("pathFormat", required: true)]
        public Input<string> PathFormat { get; set; } = null!;

        /// <summary>
        /// The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
        /// </summary>
        [Input("prefix")]
        public Input<string>? Prefix { get; set; }

        /// <summary>
        /// The name of the log project. It is the only in one Alicloud account.
        /// </summary>
        [Input("projectName", required: true)]
        public Input<string> ProjectName { get; set; } = null!;

        /// <summary>
        /// Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
        /// </summary>
        [Input("roleArn")]
        public Input<string>? RoleArn { get; set; }

        /// <summary>
        /// The suffix for the objects in which the shipped data is stored.
        /// </summary>
        [Input("suffix")]
        public Input<string>? Suffix { get; set; }

        /// <summary>
        /// This time zone that is used to format the time, `+0800` e.g.
        /// </summary>
        [Input("timeZone", required: true)]
        public Input<string> TimeZone { get; set; } = null!;

        public OssExportArgs()
        {
        }
        public static new OssExportArgs Empty => new OssExportArgs();
    }

    public sealed class OssExportState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the oss bucket.
        /// </summary>
        [Input("bucket")]
        public Input<string>? Bucket { get; set; }

        /// <summary>
        /// How often is it delivered every interval.
        /// </summary>
        [Input("bufferInterval")]
        public Input<int>? BufferInterval { get; set; }

        /// <summary>
        /// Automatically control the creation interval of delivery tasks and set the upper limit of an OSS object size (calculated in uncompressed), unit: `MB`.
        /// </summary>
        [Input("bufferSize")]
        public Input<int>? BufferSize { get; set; }

        /// <summary>
        /// OSS data storage compression method, support: `none`, `snappy`, `zstd`, `gzip`. Among them, none means that the original data is not compressed, and snappy means that the data is compressed using the snappy algorithm, which can reduce the storage space usage of the `OSS Bucket`.
        /// </summary>
        [Input("compressType")]
        public Input<string>? CompressType { get; set; }

        [Input("configColumns")]
        private InputList<Inputs.OssExportConfigColumnGetArgs>? _configColumns;

        /// <summary>
        /// Configure columns when `content_type` is `parquet` or `orc`.
        /// </summary>
        public InputList<Inputs.OssExportConfigColumnGetArgs> ConfigColumns
        {
            get => _configColumns ?? (_configColumns = new InputList<Inputs.OssExportConfigColumnGetArgs>());
            set => _configColumns = value;
        }

        /// <summary>
        /// Storage format, only supports three types: `json`, `parquet`, `orc`, `csv`.
        /// **According to the different format, please select the following parameters**
        /// </summary>
        [Input("contentType")]
        public Input<string>? ContentType { get; set; }

        [Input("csvConfigColumns")]
        private InputList<string>? _csvConfigColumns;

        /// <summary>
        /// Field configuration in csv content_type.
        /// </summary>
        public InputList<string> CsvConfigColumns
        {
            get => _csvConfigColumns ?? (_csvConfigColumns = new InputList<string>());
            set => _csvConfigColumns = value;
        }

        /// <summary>
        /// Separator configuration in csv content_type.
        /// </summary>
        [Input("csvConfigDelimiter")]
        public Input<string>? CsvConfigDelimiter { get; set; }

        /// <summary>
        /// escape in csv content_type.
        /// </summary>
        [Input("csvConfigEscape")]
        public Input<string>? CsvConfigEscape { get; set; }

        /// <summary>
        /// Indicates whether to write the field name to the CSV file, the default value is `false`.
        /// </summary>
        [Input("csvConfigHeader")]
        public Input<bool>? CsvConfigHeader { get; set; }

        /// <summary>
        /// lineFeed in csv content_type.
        /// </summary>
        [Input("csvConfigLinefeed")]
        public Input<string>? CsvConfigLinefeed { get; set; }

        /// <summary>
        /// Invalid field content in csv content_type.
        /// </summary>
        [Input("csvConfigNull")]
        public Input<string>? CsvConfigNull { get; set; }

        /// <summary>
        /// Escape character in csv content_type.
        /// </summary>
        [Input("csvConfigQuote")]
        public Input<string>? CsvConfigQuote { get; set; }

        /// <summary>
        /// The display name for oss export.
        /// </summary>
        [Input("displayName")]
        public Input<string>? DisplayName { get; set; }

        /// <summary>
        /// Delivery configuration name, it can only contain lowercase letters, numbers, dashes `-` and underscores `_`. It must start and end with lowercase letters or numbers, and the name must be 2 to 128 characters long.
        /// </summary>
        [Input("exportName")]
        public Input<string>? ExportName { get; set; }

        /// <summary>
        /// The log from when to export to oss.
        /// </summary>
        [Input("fromTime")]
        public Input<int>? FromTime { get; set; }

        /// <summary>
        /// Whether to deliver the label when `content_type` = `json`.
        /// </summary>
        [Input("jsonEnableTag")]
        public Input<bool>? JsonEnableTag { get; set; }

        /// <summary>
        /// Used for logstore reading, the role should have log read policy, such as `acs:ram::13234:role/logrole`, if `log_read_role_arn` is not set, `role_arn` is used to read logstore.
        /// </summary>
        [Input("logReadRoleArn")]
        public Input<string>? LogReadRoleArn { get; set; }

        /// <summary>
        /// The name of the log logstore.
        /// </summary>
        [Input("logstoreName")]
        public Input<string>? LogstoreName { get; set; }

        /// <summary>
        /// The OSS Bucket directory is dynamically generated according to the creation time of the export task, it cannot start with a forward slash `/`, the default value is `%Y/%m/%d/%H/%M`.
        /// </summary>
        [Input("pathFormat")]
        public Input<string>? PathFormat { get; set; }

        /// <summary>
        /// The data synchronized from Log Service to OSS will be stored in this directory of Bucket.
        /// </summary>
        [Input("prefix")]
        public Input<string>? Prefix { get; set; }

        /// <summary>
        /// The name of the log project. It is the only in one Alicloud account.
        /// </summary>
        [Input("projectName")]
        public Input<string>? ProjectName { get; set; }

        /// <summary>
        /// Used to write to oss bucket, the OSS Bucket owner creates the role mark which has the oss bucket write policy, such as `acs:ram::13234:role/logrole`.
        /// </summary>
        [Input("roleArn")]
        public Input<string>? RoleArn { get; set; }

        /// <summary>
        /// The suffix for the objects in which the shipped data is stored.
        /// </summary>
        [Input("suffix")]
        public Input<string>? Suffix { get; set; }

        /// <summary>
        /// This time zone that is used to format the time, `+0800` e.g.
        /// </summary>
        [Input("timeZone")]
        public Input<string>? TimeZone { get; set; }

        public OssExportState()
        {
        }
        public static new OssExportState Empty => new OssExportState();
    }
}
