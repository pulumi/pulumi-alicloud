// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.alicloud.gpdb;

import com.pulumi.alicloud.Utilities;
import com.pulumi.alicloud.gpdb.StreamingJobArgs;
import com.pulumi.alicloud.gpdb.inputs.StreamingJobState;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Provides a GPDB Streaming Job resource.
 * 
 * Real-time data tasks.
 * 
 * For information about GPDB Streaming Job and how to use it, see [What is Streaming Job](https://www.alibabacloud.com/help/en/).
 * 
 * &gt; **NOTE:** Available since v1.231.0.
 * 
 * ## Example Usage
 * 
 * Basic Usage
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.alicloud.vpc.Network;
 * import com.pulumi.alicloud.vpc.NetworkArgs;
 * import com.pulumi.alicloud.vpc.Switch;
 * import com.pulumi.alicloud.vpc.SwitchArgs;
 * import com.pulumi.alicloud.gpdb.Instance;
 * import com.pulumi.alicloud.gpdb.InstanceArgs;
 * import com.pulumi.alicloud.gpdb.StreamingDataService;
 * import com.pulumi.alicloud.gpdb.StreamingDataServiceArgs;
 * import com.pulumi.alicloud.gpdb.StreamingDataSource;
 * import com.pulumi.alicloud.gpdb.StreamingDataSourceArgs;
 * import com.pulumi.alicloud.gpdb.StreamingJob;
 * import com.pulumi.alicloud.gpdb.StreamingJobArgs;
 * import static com.pulumi.codegen.internal.Serialization.*;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var config = ctx.config();
 *         final var name = config.get("name").orElse("terraform-example");
 *         var defaultTXqb15 = new Network("defaultTXqb15", NetworkArgs.builder()
 *             .cidrBlock("192.168.0.0/16")
 *             .build());
 * 
 *         var defaultaSWhbT = new Switch("defaultaSWhbT", SwitchArgs.builder()
 *             .vpcId(defaultTXqb15.id())
 *             .zoneId("cn-beijing-h")
 *             .cidrBlock("192.168.1.0/24")
 *             .build());
 * 
 *         var defaulth2ghc1 = new Instance("defaulth2ghc1", InstanceArgs.builder()
 *             .instanceSpec("2C8G")
 *             .description(name)
 *             .segNodeNum(2)
 *             .segStorageType("cloud_essd")
 *             .instanceNetworkType("VPC")
 *             .dbInstanceCategory("Basic")
 *             .paymentType("PayAsYouGo")
 *             .sslEnabled(0)
 *             .engineVersion("6.0")
 *             .zoneId("cn-beijing-h")
 *             .vswitchId(defaultaSWhbT.id())
 *             .storageSize(50)
 *             .masterCu(4)
 *             .vpcId(defaultTXqb15.id())
 *             .dbInstanceMode("StorageElastic")
 *             .engine("gpdb")
 *             .build());
 * 
 *         var default2dUszY = new StreamingDataService("default2dUszY", StreamingDataServiceArgs.builder()
 *             .serviceName("example")
 *             .dbInstanceId(defaulth2ghc1.id())
 *             .serviceDescription("example")
 *             .serviceSpec("8")
 *             .build());
 * 
 *         var defaultcDQItu = new StreamingDataSource("defaultcDQItu", StreamingDataSourceArgs.builder()
 *             .dbInstanceId(defaulth2ghc1.id())
 *             .dataSourceName("example")
 *             .dataSourceConfig(serializeJson(
 *                 jsonObject(
 *                     jsonProperty("brokers", "alikafka-post-cn-g4t3t4eod004-1-vpc.alikafka.aliyuncs.com:9092,alikafka-post-cn-g4t3t4eod004-2-vpc.alikafka.aliyuncs.com:9092,alikafka-post-cn-g4t3t4eod004-3-vpc.alikafka.aliyuncs.com:9092"),
 *                     jsonProperty("delimiter", "|"),
 *                     jsonProperty("format", "delimited"),
 *                     jsonProperty("topic", "ziyuan_example")
 *                 )))
 *             .dataSourceType("kafka")
 *             .dataSourceDescription("example")
 *             .serviceId(default2dUszY.serviceId())
 *             .build());
 * 
 *         var default_ = new StreamingJob("default", StreamingJobArgs.builder()
 *             .account("example_001")
 *             .destSchema("public")
 *             .mode("professional")
 *             .jobName("example-kafka")
 *             .jobDescription("example-kafka")
 *             .destDatabase("adb_sampledata_tpch")
 *             .dbInstanceId(defaulth2ghc1.id())
 *             .destTable("customer")
 *             .dataSourceId(defaultcDQItu.dataSourceId())
 *             .password("example_001")
 *             .jobConfig("""
 * ATABASE: adb_sampledata_tpch
 * USER: example_001
 * PASSWORD: example_001
 * HOST: gp-2zean69451zsjj139-master.gpdb.rds.aliyuncs.com
 * PORT: 5432
 * KAFKA:
 *   INPUT:
 *     SOURCE:
 *       BROKERS: alikafka-post-cn-3mp3t4ekq004-1-vpc.alikafka.aliyuncs.com:9092
 *       TOPIC: ziyuan_example
 *       FALLBACK_OFFSET: LATEST
 *     KEY:
 *       COLUMNS:
 *       - NAME: c_custkey
 *         TYPE: int
 *       FORMAT: delimited
 *       DELIMITED_OPTION:
 *         DELIMITER: \'|\'
 *     VALUE:
 *       COLUMNS:
 *       - NAME: c_comment
 *         TYPE: varchar
 *       FORMAT: delimited
 *       DELIMITED_OPTION:
 *         DELIMITER: \'|\'
 *     ERROR_LIMIT: 10
 *   OUTPUT:
 *     SCHEMA: public
 *     TABLE: customer
 *     MODE: MERGE
 *     MATCH_COLUMNS:
 *     - c_custkey
 *     ORDER_COLUMNS:
 *     - c_custkey
 *     UPDATE_COLUMNS:
 *     - c_custkey
 *     MAPPING:
 *     - NAME: c_custkey
 *       EXPRESSION: c_custkey
 *   COMMIT:
 *     MAX_ROW: 1000
 *     MINIMAL_INTERVAL: 1000
 *     CONSISTENCY: ATLEAST
 *   POLL:
 *     BATCHSIZE: 1000
 *     TIMEOUT: 1000
 *   PROPERTIES:
 *     group.id: ziyuan_example_01
 *             """)
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * GPDB Streaming Job can be imported using the id, e.g.
 * 
 * ```sh
 * $ pulumi import alicloud:gpdb/streamingJob:StreamingJob example &lt;db_instance_id&gt;:&lt;job_id&gt;
 * ```
 * 
 */
@ResourceType(type="alicloud:gpdb/streamingJob:StreamingJob")
public class StreamingJob extends com.pulumi.resources.CustomResource {
    /**
     * The name of the database account.
     * 
     */
    @Export(name="account", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> account;

    /**
     * @return The name of the database account.
     * 
     */
    public Output<Optional<String>> account() {
        return Codegen.optional(this.account);
    }
    /**
     * The delivery guarantee setting.
     * 
     * Valid values:
     * 
     * - ATLEAST
     * - EXACTLY
     * 
     */
    @Export(name="consistency", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> consistency;

    /**
     * @return The delivery guarantee setting.
     * 
     * Valid values:
     * 
     * - ATLEAST
     * - EXACTLY
     * 
     */
    public Output<Optional<String>> consistency() {
        return Codegen.optional(this.consistency);
    }
    /**
     * The creation time of the resource
     * 
     */
    @Export(name="createTime", refs={String.class}, tree="[0]")
    private Output<String> createTime;

    /**
     * @return The creation time of the resource
     * 
     */
    public Output<String> createTime() {
        return this.createTime;
    }
    /**
     * The data source ID.
     * 
     */
    @Export(name="dataSourceId", refs={String.class}, tree="[0]")
    private Output<String> dataSourceId;

    /**
     * @return The data source ID.
     * 
     */
    public Output<String> dataSourceId() {
        return this.dataSourceId;
    }
    /**
     * The instance ID.
     * 
     */
    @Export(name="dbInstanceId", refs={String.class}, tree="[0]")
    private Output<String> dbInstanceId;

    /**
     * @return The instance ID.
     * 
     */
    public Output<String> dbInstanceId() {
        return this.dbInstanceId;
    }
    /**
     * Target Field
     * 
     */
    @Export(name="destColumns", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> destColumns;

    /**
     * @return Target Field
     * 
     */
    public Output<Optional<List<String>>> destColumns() {
        return Codegen.optional(this.destColumns);
    }
    /**
     * The name of the destination database.
     * 
     */
    @Export(name="destDatabase", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> destDatabase;

    /**
     * @return The name of the destination database.
     * 
     */
    public Output<Optional<String>> destDatabase() {
        return Codegen.optional(this.destDatabase);
    }
    /**
     * Target Schema
     * 
     */
    @Export(name="destSchema", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> destSchema;

    /**
     * @return Target Schema
     * 
     */
    public Output<Optional<String>> destSchema() {
        return Codegen.optional(this.destSchema);
    }
    /**
     * The name of the destination table.
     * 
     */
    @Export(name="destTable", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> destTable;

    /**
     * @return The name of the destination table.
     * 
     */
    public Output<Optional<String>> destTable() {
        return Codegen.optional(this.destTable);
    }
    /**
     * The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
     * 
     */
    @Export(name="errorLimitCount", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> errorLimitCount;

    /**
     * @return The number of allowed error rows. Write failures occur when Kafka data does not match the destination table in AnalyticDB for PostgreSQL. If the specified value is exceeded, the job fails.
     * 
     */
    public Output<Optional<Integer>> errorLimitCount() {
        return Codegen.optional(this.errorLimitCount);
    }
    /**
     * Automatic offset reset
     * 
     */
    @Export(name="fallbackOffset", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> fallbackOffset;

    /**
     * @return Automatic offset reset
     * 
     */
    public Output<Optional<String>> fallbackOffset() {
        return Codegen.optional(this.fallbackOffset);
    }
    /**
     * Group Name
     * 
     */
    @Export(name="groupName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> groupName;

    /**
     * @return Group Name
     * 
     */
    public Output<Optional<String>> groupName() {
        return Codegen.optional(this.groupName);
    }
    /**
     * The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
     * 
     */
    @Export(name="jobConfig", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> jobConfig;

    /**
     * @return The YAML configuration file of the job. This parameter must be specified when Mode is set to professional.
     * 
     */
    public Output<Optional<String>> jobConfig() {
        return Codegen.optional(this.jobConfig);
    }
    /**
     * The description of the job.
     * 
     */
    @Export(name="jobDescription", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> jobDescription;

    /**
     * @return The description of the job.
     * 
     */
    public Output<Optional<String>> jobDescription() {
        return Codegen.optional(this.jobDescription);
    }
    /**
     * The job ID.
     * 
     */
    @Export(name="jobId", refs={String.class}, tree="[0]")
    private Output<String> jobId;

    /**
     * @return The job ID.
     * 
     */
    public Output<String> jobId() {
        return this.jobId;
    }
    /**
     * The name of the job.
     * 
     */
    @Export(name="jobName", refs={String.class}, tree="[0]")
    private Output<String> jobName;

    /**
     * @return The name of the job.
     * 
     */
    public Output<String> jobName() {
        return this.jobName;
    }
    /**
     * Match Field
     * 
     */
    @Export(name="matchColumns", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> matchColumns;

    /**
     * @return Match Field
     * 
     */
    public Output<Optional<List<String>>> matchColumns() {
        return Codegen.optional(this.matchColumns);
    }
    /**
     * The configuration mode. Valid values:
     * 
     * 1.  basic: In basic mode, you must configure the configuration parameters.
     * 
     * 2.  professional: In professional mode, you can submit a YAML configuration file.
     * 
     */
    @Export(name="mode", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> mode;

    /**
     * @return The configuration mode. Valid values:
     * 
     * 1.  basic: In basic mode, you must configure the configuration parameters.
     * 
     * 2.  professional: In professional mode, you can submit a YAML configuration file.
     * 
     */
    public Output<Optional<String>> mode() {
        return Codegen.optional(this.mode);
    }
    /**
     * The password of the database account.
     * 
     */
    @Export(name="password", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> password;

    /**
     * @return The password of the database account.
     * 
     */
    public Output<Optional<String>> password() {
        return Codegen.optional(this.password);
    }
    /**
     * Source Field
     * 
     */
    @Export(name="srcColumns", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> srcColumns;

    /**
     * @return Source Field
     * 
     */
    public Output<Optional<List<String>>> srcColumns() {
        return Codegen.optional(this.srcColumns);
    }
    /**
     * Service status, value:
     * 
     */
    @Export(name="status", refs={String.class}, tree="[0]")
    private Output<String> status;

    /**
     * @return Service status, value:
     * 
     */
    public Output<String> status() {
        return this.status;
    }
    /**
     * Specifies whether to test the real-time job. Valid values:
     * 
     * - true
     * - false
     * 
     * Default value: false.
     * 
     */
    @Export(name="tryRun", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> tryRun;

    /**
     * @return Specifies whether to test the real-time job. Valid values:
     * 
     * - true
     * - false
     * 
     * Default value: false.
     * 
     */
    public Output<Optional<Boolean>> tryRun() {
        return Codegen.optional(this.tryRun);
    }
    /**
     * Update Field
     * 
     */
    @Export(name="updateColumns", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> updateColumns;

    /**
     * @return Update Field
     * 
     */
    public Output<Optional<List<String>>> updateColumns() {
        return Codegen.optional(this.updateColumns);
    }
    /**
     * The write mode.
     * 
     * Valid values:
     * 
     * - insert
     * - update
     * - merge
     * 
     */
    @Export(name="writeMode", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> writeMode;

    /**
     * @return The write mode.
     * 
     * Valid values:
     * 
     * - insert
     * - update
     * - merge
     * 
     */
    public Output<Optional<String>> writeMode() {
        return Codegen.optional(this.writeMode);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public StreamingJob(java.lang.String name) {
        this(name, StreamingJobArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public StreamingJob(java.lang.String name, StreamingJobArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public StreamingJob(java.lang.String name, StreamingJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("alicloud:gpdb/streamingJob:StreamingJob", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private StreamingJob(java.lang.String name, Output<java.lang.String> id, @Nullable StreamingJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("alicloud:gpdb/streamingJob:StreamingJob", name, state, makeResourceOptions(options, id), false);
    }

    private static StreamingJobArgs makeArgs(StreamingJobArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? StreamingJobArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static StreamingJob get(java.lang.String name, Output<java.lang.String> id, @Nullable StreamingJobState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new StreamingJob(name, id, state, options);
    }
}
