// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.alicloud.eflo.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Integer;
import java.lang.String;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class ExperimentPlanTemplateTemplatePipelineEnvParams {
    /**
     * @return Number of central processing units (CPUs) allocated. This parameter affects the processing power of the computation, especially in tasks that require a large amount of parallel processing.
     * 
     */
    private Integer cpuPerWorker;
    /**
     * @return The version of CUDA(Compute Unified Device Architecture) used. CUDA is a parallel computing platform and programming model provided by NVIDIA. A specific version may affect the available GPU functions and performance optimization.
     * 
     */
    private @Nullable String cudaVersion;
    /**
     * @return The version of the GPU driver used. Driver version may affect GPU performance and compatibility, so it is important to ensure that the correct version is used
     * 
     */
    private @Nullable String gpuDriverVersion;
    /**
     * @return Number of graphics processing units (GPUs). GPUs are a key component in deep learning and large-scale data processing, so this parameter is very important for tasks that require graphics-accelerated computing.
     * 
     */
    private Integer gpuPerWorker;
    /**
     * @return The amount of memory available. Memory size has an important impact on the performance and stability of the program, especially when dealing with large data sets or high-dimensional data.
     * 
     */
    private Integer memoryPerWorker;
    /**
     * @return The NVIDIA Collective Communications Library(NCCL) version used. NCCL is a library for multi-GPU and multi-node communication. This parameter is particularly important for optimizing data transmission in distributed computing.
     * 
     */
    private @Nullable String ncclVersion;
    /**
     * @return The version of the PyTorch framework used. PyTorch is a widely used deep learning library, and differences between versions may affect the performance and functional support of model training and inference.
     * 
     */
    private @Nullable String pyTorchVersion;
    /**
     * @return Shared memory GB allocation
     * 
     */
    private Integer shareMemory;
    /**
     * @return The total number of nodes. This parameter directly affects the parallelism and computing speed of the task, and a higher number of working nodes usually accelerates the completion of the task.
     * 
     */
    private Integer workerNum;

    private ExperimentPlanTemplateTemplatePipelineEnvParams() {}
    /**
     * @return Number of central processing units (CPUs) allocated. This parameter affects the processing power of the computation, especially in tasks that require a large amount of parallel processing.
     * 
     */
    public Integer cpuPerWorker() {
        return this.cpuPerWorker;
    }
    /**
     * @return The version of CUDA(Compute Unified Device Architecture) used. CUDA is a parallel computing platform and programming model provided by NVIDIA. A specific version may affect the available GPU functions and performance optimization.
     * 
     */
    public Optional<String> cudaVersion() {
        return Optional.ofNullable(this.cudaVersion);
    }
    /**
     * @return The version of the GPU driver used. Driver version may affect GPU performance and compatibility, so it is important to ensure that the correct version is used
     * 
     */
    public Optional<String> gpuDriverVersion() {
        return Optional.ofNullable(this.gpuDriverVersion);
    }
    /**
     * @return Number of graphics processing units (GPUs). GPUs are a key component in deep learning and large-scale data processing, so this parameter is very important for tasks that require graphics-accelerated computing.
     * 
     */
    public Integer gpuPerWorker() {
        return this.gpuPerWorker;
    }
    /**
     * @return The amount of memory available. Memory size has an important impact on the performance and stability of the program, especially when dealing with large data sets or high-dimensional data.
     * 
     */
    public Integer memoryPerWorker() {
        return this.memoryPerWorker;
    }
    /**
     * @return The NVIDIA Collective Communications Library(NCCL) version used. NCCL is a library for multi-GPU and multi-node communication. This parameter is particularly important for optimizing data transmission in distributed computing.
     * 
     */
    public Optional<String> ncclVersion() {
        return Optional.ofNullable(this.ncclVersion);
    }
    /**
     * @return The version of the PyTorch framework used. PyTorch is a widely used deep learning library, and differences between versions may affect the performance and functional support of model training and inference.
     * 
     */
    public Optional<String> pyTorchVersion() {
        return Optional.ofNullable(this.pyTorchVersion);
    }
    /**
     * @return Shared memory GB allocation
     * 
     */
    public Integer shareMemory() {
        return this.shareMemory;
    }
    /**
     * @return The total number of nodes. This parameter directly affects the parallelism and computing speed of the task, and a higher number of working nodes usually accelerates the completion of the task.
     * 
     */
    public Integer workerNum() {
        return this.workerNum;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(ExperimentPlanTemplateTemplatePipelineEnvParams defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private Integer cpuPerWorker;
        private @Nullable String cudaVersion;
        private @Nullable String gpuDriverVersion;
        private Integer gpuPerWorker;
        private Integer memoryPerWorker;
        private @Nullable String ncclVersion;
        private @Nullable String pyTorchVersion;
        private Integer shareMemory;
        private Integer workerNum;
        public Builder() {}
        public Builder(ExperimentPlanTemplateTemplatePipelineEnvParams defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.cpuPerWorker = defaults.cpuPerWorker;
    	      this.cudaVersion = defaults.cudaVersion;
    	      this.gpuDriverVersion = defaults.gpuDriverVersion;
    	      this.gpuPerWorker = defaults.gpuPerWorker;
    	      this.memoryPerWorker = defaults.memoryPerWorker;
    	      this.ncclVersion = defaults.ncclVersion;
    	      this.pyTorchVersion = defaults.pyTorchVersion;
    	      this.shareMemory = defaults.shareMemory;
    	      this.workerNum = defaults.workerNum;
        }

        @CustomType.Setter
        public Builder cpuPerWorker(Integer cpuPerWorker) {
            if (cpuPerWorker == null) {
              throw new MissingRequiredPropertyException("ExperimentPlanTemplateTemplatePipelineEnvParams", "cpuPerWorker");
            }
            this.cpuPerWorker = cpuPerWorker;
            return this;
        }
        @CustomType.Setter
        public Builder cudaVersion(@Nullable String cudaVersion) {

            this.cudaVersion = cudaVersion;
            return this;
        }
        @CustomType.Setter
        public Builder gpuDriverVersion(@Nullable String gpuDriverVersion) {

            this.gpuDriverVersion = gpuDriverVersion;
            return this;
        }
        @CustomType.Setter
        public Builder gpuPerWorker(Integer gpuPerWorker) {
            if (gpuPerWorker == null) {
              throw new MissingRequiredPropertyException("ExperimentPlanTemplateTemplatePipelineEnvParams", "gpuPerWorker");
            }
            this.gpuPerWorker = gpuPerWorker;
            return this;
        }
        @CustomType.Setter
        public Builder memoryPerWorker(Integer memoryPerWorker) {
            if (memoryPerWorker == null) {
              throw new MissingRequiredPropertyException("ExperimentPlanTemplateTemplatePipelineEnvParams", "memoryPerWorker");
            }
            this.memoryPerWorker = memoryPerWorker;
            return this;
        }
        @CustomType.Setter
        public Builder ncclVersion(@Nullable String ncclVersion) {

            this.ncclVersion = ncclVersion;
            return this;
        }
        @CustomType.Setter
        public Builder pyTorchVersion(@Nullable String pyTorchVersion) {

            this.pyTorchVersion = pyTorchVersion;
            return this;
        }
        @CustomType.Setter
        public Builder shareMemory(Integer shareMemory) {
            if (shareMemory == null) {
              throw new MissingRequiredPropertyException("ExperimentPlanTemplateTemplatePipelineEnvParams", "shareMemory");
            }
            this.shareMemory = shareMemory;
            return this;
        }
        @CustomType.Setter
        public Builder workerNum(Integer workerNum) {
            if (workerNum == null) {
              throw new MissingRequiredPropertyException("ExperimentPlanTemplateTemplatePipelineEnvParams", "workerNum");
            }
            this.workerNum = workerNum;
            return this;
        }
        public ExperimentPlanTemplateTemplatePipelineEnvParams build() {
            final var _resultValue = new ExperimentPlanTemplateTemplatePipelineEnvParams();
            _resultValue.cpuPerWorker = cpuPerWorker;
            _resultValue.cudaVersion = cudaVersion;
            _resultValue.gpuDriverVersion = gpuDriverVersion;
            _resultValue.gpuPerWorker = gpuPerWorker;
            _resultValue.memoryPerWorker = memoryPerWorker;
            _resultValue.ncclVersion = ncclVersion;
            _resultValue.pyTorchVersion = pyTorchVersion;
            _resultValue.shareMemory = shareMemory;
            _resultValue.workerNum = workerNum;
            return _resultValue;
        }
    }
}
